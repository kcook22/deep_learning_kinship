{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kinship_Recognition_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4g8yMLqtS3W"
      },
      "source": [
        "# **Large-Scale Kinship Recognition Data Challenge: Kinship Verification STARTER NOTEBOOK**\n",
        "\n",
        "We provide framework code to get you started on the competition. The notebook is broken up into three main sections. \n",
        "1. Data Loading & Visualizing\n",
        "2. Data Generator & Model Building\n",
        "3. Training & Testing Model\n",
        "\n",
        "We have done the majority of the heavy lifting by making the data easily and readily accessible through Google Drive. Furthermore, we have made the task easier by creating a dataloader and fully trained end-to-end model that predicts a binary label (0 or 1) denoting whether two faces share a kinship relation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjYhbL1xxgfU",
        "outputId": "144c2f29-7f16-471a-990a-2a0abfb51e8e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LDDgTAe2w0H"
      },
      "source": [
        "**WARNING: IF YOU HAVE NOT DONE SO**\n",
        "\n",
        "Change to GPU:\n",
        "\n",
        "Runtime --> Change Runtime Type --> GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWf8L2-Ru6ZE"
      },
      "source": [
        "Mount to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ribPmcZau-vR"
      },
      "source": [
        "Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS3ZhSjIAGgt"
      },
      "source": [
        "%%capture\n",
        "!pip install keras_vggface\n",
        "!pip install keras_applications"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4yFxckrAAZx"
      },
      "source": [
        "from collections import defaultdict\n",
        "from glob import glob\n",
        "from random import choice, sample\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.vggface import VGGFace"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXViO7APvFYW"
      },
      "source": [
        "train_relationships.csv contains pairs of image paths which are positive samples (related to each other).\n",
        "\n",
        "train-faces contains the images for training itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItZNSTCVAESV"
      },
      "source": [
        "# Modify paths as per your method of saving them\n",
        "train_file_path = \"/content/drive/MyDrive/Kinship Recognition Starter/train_ds.csv\"\n",
        "train_folders_path = \"/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/\"\n",
        "# All images belonging to families F09** will be used to create the validation set while training the model\n",
        "# For final submission, you can add these to the training data as well\n",
        "val_famillies = \"F09\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLuyuKKBAWMf"
      },
      "source": [
        "all_images = glob(train_folders_path + \"*/*/*.jpg\")\n",
        "\n",
        "train_images = [x for x in all_images if val_famillies not in x]\n",
        "val_images = [x for x in all_images if val_famillies in x]\n",
        "\n",
        "train_person_to_images_map = defaultdict(list)\n",
        "\n",
        "ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]\n",
        "\n",
        "for x in train_images:\n",
        "    train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
        "\n",
        "val_person_to_images_map = defaultdict(list)\n",
        "\n",
        "for x in val_images:\n",
        "    val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HQExgwH95NU",
        "outputId": "7323d71b-e3df-4fd9-e4b8-25d70429d101"
      },
      "source": [
        "all_images"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03496_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03500_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03497_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03501_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03492_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03499_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03494_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03493_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03495_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03498_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03496_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03500_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03494_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03498_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03495_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID4/P03501_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID4/P03494_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID4/P03495_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID5/P03500_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID5/P03497_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID5/P03498_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID2/P03499_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID2/P03492_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID2/P03493_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09897_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09901_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09900_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09896_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09903_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09895_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09902_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09899_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09897_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09901_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09900_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09903_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09898_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09902_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09904_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID4/P09900_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID4/P09898_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID4/P09904_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID4/P09902_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09901_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09897_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09896_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09895_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09898_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09904_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09899_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05980_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05977_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05971_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05981_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05973_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05982_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05978_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05975_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05983_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05972_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05979_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05974_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05971_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05982_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05973_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05975_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05972_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05971_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05980_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05977_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05975_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05978_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05972_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05974_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05979_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05980_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05971_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05977_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05975_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05978_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05972_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05974_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05971_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05981_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05973_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05983_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05972_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09805_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09811_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09809_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09810_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09813_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09814_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09806_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09812_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID6/P09809_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID3/P09808_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID3/P09813_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID3/P09807_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID4/P09811_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID4/P09809_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID4/P09812_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID5/P09809_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID5/P09812_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09808_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09805_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09810_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09809_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09807_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09813_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09812_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09814_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09806_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID7/P08334_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID8/P08336_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID1/P08334_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID1/P08337_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID1/P08336_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID1/P08341_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID6/P08334_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID3/P08333_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID3/P08334_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID3/P08341_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID4/P08334_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID4/P08341_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID5/P08333_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID5/P08334_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID2/P08337_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID2/P08336_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01390_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09130_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09129_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01396_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09125_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09131_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09128_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01397_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01392_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09126_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01399_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01394_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01393_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09127_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01398_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01395_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01389_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01390_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09130_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01396_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09125_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01397_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09134_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01399_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01394_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09132_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09133_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID4/P01397_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID4/P01398_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID5/P01398_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P01389_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P09125_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P09132_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P01393_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P01395_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID7/P07713_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID9/P07717_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID8/P07717_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07712_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07714_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07713_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07715_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07710_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07716_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07708_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07711_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID6/P07713_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07712_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07714_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07710_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07709_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07716_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07708_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07711_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07717_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07712_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07714_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07715_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07709_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07710_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07711_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID5/P07713_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07712_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07714_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07709_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07710_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07716_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07708_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07415_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07434_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07432_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07426_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07414_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07427_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07433_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07430_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07429_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07417_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07416_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07431_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07428_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID3/P07415_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID3/P07414_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID3/P07416_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID4/P07415_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID4/P07414_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID4/P07417_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID4/P07416_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07415_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07426_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07432_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07414_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07433_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07427_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07429_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07416_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07431_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07428_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04205_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04208_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04211_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04210_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04204_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04207_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04213_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04206_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04212_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04208_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04211_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04210_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04209_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04213_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04212_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04205_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04208_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04204_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04209_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04207_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04213_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04206_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04212_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01792_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01794_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01793_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01795_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01803_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01796_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01804_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID3/P01795_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID3/P01804_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID4/P01797_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01792_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01794_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01793_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01795_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01796_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID7/P07666_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID7/P07665_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07658_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07666_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07663_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07665_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07662_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07664_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID6/P07666_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID6/P07665_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID5/P07663_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID5/P07662_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID5/P07664_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID2/P07658_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID2/P07662_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID2/P07664_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10437_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10437_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10429_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10429_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10435_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10435_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10433_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10433_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10437_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10437_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10429_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10429_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10435_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10433_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10435_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10433_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10437_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10437_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10429_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10429_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10433_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10433_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10435_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10435_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10428_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10432_face9.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10431_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10431_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10428_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10430_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10436_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10430_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P06405_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P06405_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P06410_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10432_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10432_face8.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10437_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10437_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10429_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10436_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10429_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10433_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10433_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10435_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10432_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID11/P10432_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID11/P10432_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10428_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10431_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10428_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06401_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10431_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06403_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06403_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06409_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06404_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06409_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10434_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10434_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10431_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06401_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10428_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10428_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06401_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10431_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10436_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10436_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06403_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06403_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06404_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06409_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06409_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10434_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10428_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10431_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10437_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10431_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10429_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10429_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10436_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10435_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10433_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10433_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10432_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10432_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10431_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10437_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10437_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10428_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10431_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10429_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10429_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10436_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10433_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10433_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10435_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10432_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10432_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID2/P10436_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID2/P10430_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10431_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10428_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10431_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10428_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10430_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10430_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID13/P10430_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID13/P10430_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID14/P10430_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID7/P10557_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID1/P10551_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID1/P10554_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID1/P10552_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID1/P10553_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID6/P10556_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID6/P10555_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID3/P10551_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID3/P10553_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID4/P10552_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID4/P10558_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID5/P10560_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID5/P10553_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID2/P10551_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID2/P10559_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID7/P04136_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID8/P04136_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04131_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04137_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04129_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04130_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04136_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04127_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04138_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04132_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04134_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID6/P04127_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID6/P04132_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID3/P04131_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID3/P04129_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID4/P04137_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID4/P04127_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID4/P04132_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID4/P04134_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID5/P04138_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID5/P04127_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID5/P04132_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID5/P04134_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID2/P04131_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID2/P04129_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID2/P04130_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID1/P01819_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID1/P01817_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID1/P01816_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID3/P01816_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID4/P01819_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID2/P01817_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID2/P01816_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08436_face11.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08417_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08430_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08416_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08437_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08431_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08410_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08415_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08418_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08434_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08432_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08413_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08419_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08438_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08412_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08411_face8.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID3/P08441_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID3/P08437_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID3/P08410_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID3/P08442_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08417_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08440_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08439_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08418_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08412_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08417_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08411_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08436_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08430_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08437_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08416_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08431_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08418_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08434_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08415_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08413_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08432_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08438_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09817_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09824_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09823_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09816_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09818_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09815_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09820_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09819_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09817_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09822_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09824_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09823_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09818_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09820_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09819_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID4/P09824_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID4/P09821_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID2/P09815_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID1/P12238_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID1/P12239_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID1/P12237_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12249_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12248_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12245_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12246_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12247_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID3/P12242_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID3/P12243_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID4/P12243_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID5/P12244_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID5/P12243_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12242_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12243_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12245_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12240_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12246_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12241_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09576_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09581_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09577_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09580_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09579_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09583_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09575_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09578_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09582_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09584_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09576_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09577_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09583_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09578_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09575_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09584_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09581_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09577_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09580_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09579_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09575_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09582_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID7/P07904_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID7/P07879_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID9/P07904_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID9/P07879_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID8/P07879_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07895_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07905_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07908_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07893_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07880_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07899_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07902_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07886_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07909_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07892_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07883_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07901_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07897_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07885_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07891_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07896_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07878_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07884_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID6/P07904_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID6/P07879_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID10/P07881_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID10/P07887_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07895_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07887_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07905_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07893_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07881_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07902_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07892_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07880_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07909_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07886_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07894_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07897_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07901_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07883_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07907_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07891_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07896_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07878_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07900_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07884_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07895_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07898_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07893_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07894_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07899_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07880_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07909_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07892_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07901_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07897_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07907_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07888_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07891_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07900_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07896_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07890_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07878_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID5/P07878_face8.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07895_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07898_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07908_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07893_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07905_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07880_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07899_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07892_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07909_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07904_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07894_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07901_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07897_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07891_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07879_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07907_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07883_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07896_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07900_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07878_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07889_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID7/P07978_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07979_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07975_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07982_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07976_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07977_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID6/P07982_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID3/P07978_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID3/P07976_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID4/P07977_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID5/P07979_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID2/P07975_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05615_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05611_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05610_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05609_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05616_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID3/P05616_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05615_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05611_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05610_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05609_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05616_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01700_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01701_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01707_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01699_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01702_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01704_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01698_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01703_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01705_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01700_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01701_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01707_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01699_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01704_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01703_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01701_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01702_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01704_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01698_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01705_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05338_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05335_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05336_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05330_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05337_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID6/P05337_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID3/P05330_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID4/P05330_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID2/P05338_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID2/P05335_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID2/P05336_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID2/P05330_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID7/P04196_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID7/P04201_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID7/P04195_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID8/P04196_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID8/P04195_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04203_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04202_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04197_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04199_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04194_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04201_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04195_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04198_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04200_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID6/P04201_face8.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04196_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04197_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04199_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04201_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04198_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04200_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04195_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04196_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04197_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04201_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04195_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04200_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04196_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04199_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04201_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04200_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04195_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04203_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04197_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04202_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04201_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04194_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04200_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04195_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID1/P10516_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID1/P10522_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID1/P10529_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID3/P10526_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID3/P10516_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID3/P10517_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10519_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10521_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10527_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10518_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10520_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10526_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10528_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10525_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID5/P10523_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID5/P10524_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID2/P10516_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID2/P10522_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID2/P10529_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04741_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04736_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04746_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04740_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04745_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04732_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04739_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04744_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04733_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04738_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04742_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID3/P04733_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04741_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04746_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04740_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04745_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04743_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04744_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04742_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID5/P04745_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID5/P04744_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04736_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04737_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04732_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04739_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04733_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04738_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07195_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07193_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07194_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07192_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07188_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07191_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07196_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07189_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07190_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID3/P07193_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID3/P07194_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID3/P07192_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID3/P07191_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID4/P07195_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID4/P07194_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID4/P07196_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID2/P07194_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID2/P07188_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID2/P07189_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID2/P07190_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04956_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04950_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04949_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04957_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04951_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04953_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID3/P04954_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID3/P04952_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID3/P04953_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID4/P04954_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID4/P04952_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID4/P04955_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID4/P04953_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04956_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04950_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04949_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04957_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04951_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04954_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04952_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04955_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02410_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02405_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02411_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02408_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02412_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02414_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02407_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02413_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID3/P02410_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID3/P02408_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID3/P02412_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID3/P02413_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID4/P02409_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID4/P02411_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID5/P02409_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID5/P02411_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID2/P02410_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID2/P02405_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID2/P02414_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID2/P02407_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00221_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00227_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00220_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00226_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00223_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00225_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00228_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00222_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00224_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00229_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID3/P00221_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID3/P00222_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID3/P00229_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID4/P00225_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID4/P00224_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID4/P00229_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID5/P00228_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID2/P00227_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID2/P00220_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID2/P00226_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID2/P00223_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID7/P04718_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04717_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04720_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04718_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04715_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04719_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04712_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04721_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04714_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID3/P04712_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID3/P04714_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID3/P04721_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID4/P04720_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID4/P04715_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID4/P04714_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04717_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04712_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04719_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04721_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04714_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07041_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07036_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07047_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07040_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07037_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07034_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07039_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07045_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07035_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07038_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07042_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07033_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07044_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07041_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07036_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07040_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07037_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07039_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07034_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07043_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07045_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07035_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07038_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07044_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07036_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07041_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07037_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07040_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07046_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07039_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07034_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07038_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07035_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07041_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07040_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07037_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07039_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07036_face9.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07038_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07035_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07036_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07041_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07047_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07037_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07040_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07046_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07039_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07043_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07035_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07042_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07033_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07038_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08740_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08731_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08737_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08736_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08733_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08735_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08738_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08732_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08739_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08734_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID3/P08731_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID3/P08735_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID3/P08740_face10.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID3/P08739_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08731_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08737_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08740_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08736_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08733_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08735_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08732_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08734_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08731_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08736_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08733_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08738_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08735_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08734_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08740_face9.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06585_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06579_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06581_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06577_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06586_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06580_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06583_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06584_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06578_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06582_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06577_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06579_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06585_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06583_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06578_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06584_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06582_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06581_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06577_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06586_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06580_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02577_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02571_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02568_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02569_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02575_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02573_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02572_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID3/P02577_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID3/P02568_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID3/P02576_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID3/P02569_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID4/P02571_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID4/P02570_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID4/P02574_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID5/P02573_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02577_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02568_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02571_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02576_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02570_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02569_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02575_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02574_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02572_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00727_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00719_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00721_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00720_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00728_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00725_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00723_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00729_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00724_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00722_face3.jpg',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSI5FN3RAXXp"
      },
      "source": [
        "relationships = pd.read_csv(train_file_path)\n",
        "relationships = list(zip(relationships.p1.values, relationships.p2.values, relationships.relationship.values))\n",
        "relationships = [(x[0],x[1],x[2]) for x in relationships if x[0][:10] in ppl and x[1][:10] in ppl]\n",
        "\n",
        "train = [x for x in relationships if val_famillies not in x[0]]\n",
        "val = [x for x in relationships if val_famillies in x[0]]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KfHltcuAZcB"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "def read_img(path):\n",
        "    img = image.load_img(path, target_size=(224, 224))\n",
        "    img = np.array(img).astype(np.float)\n",
        "    return preprocess_input(img, version=2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5k69UJzvb26"
      },
      "source": [
        "Define a data generator. Here our data generator will generate a batch of examples which will be used by our model in training. It will generate two images, one for each in the pair as well as a label associated with it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcAZG7JYAdhY"
      },
      "source": [
        "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
        "    ppl = list(person_to_images_map.keys())\n",
        "    while True:\n",
        "        batch_tuples = sample(list_tuples, batch_size)\n",
        "        \n",
        "        # All the samples are taken from train_ds.csv, labels are in the labels column\n",
        "        labels = []\n",
        "        for tup in batch_tuples:\n",
        "          labels.append(tup[2])\n",
        "\n",
        "        X1 = [x[0] for x in batch_tuples]\n",
        "        X1 = np.array([read_img(train_folders_path + x) for x in X1])\n",
        "\n",
        "        X2 = [x[1] for x in batch_tuples]\n",
        "        X2 = np.array([read_img(train_folders_path + x) for x in X2])\n",
        "\n",
        "        yield [X1, X2], np.array(labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvPvyRzBw-nt"
      },
      "source": [
        "Here is an ensemble model built with two resnet-50 architectures, pre-trained, with which we can apply transfer leraning on. This model achieves the baseline and the goal is to expand on this work. There have been papers exploring different architectures as well as introducing BatchNormalization among many other techniques to improve how well the model recognizes kinship between two faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BBZJpieAi7Y"
      },
      "source": [
        "def baseline_model():\n",
        "    input_1 = Input(shape=(224, 224, 3))\n",
        "    input_2 = Input(shape=(224, 224, 3))\n",
        "\n",
        "    base_model = VGGFace(model='resnet50', include_top=False)\n",
        "\n",
        "    for x in base_model.layers[:-3]:\n",
        "        x.trainable = True\n",
        "\n",
        "    x1 = base_model(input_1)\n",
        "    x2 = base_model(input_2)\n",
        "\n",
        "    x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n",
        "    x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
        "\n",
        "    x3 = Subtract()([x1, x2])\n",
        "    x3 = Multiply()([x3, x3])\n",
        "\n",
        "    x = Multiply()([x1, x2])\n",
        "\n",
        "    x = Concatenate(axis=-1)([x, x3])\n",
        "\n",
        "    x = Dense(100, activation=\"relu\")(x)\n",
        "    x = Dropout(0.05)(x)\n",
        "    out = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model([input_1, input_2], out)\n",
        "\n",
        "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC3TNCLWx5RC"
      },
      "source": [
        "Save the best model to your drive after each training epoch so that you can come back to it. ReduceLROnPlateau reduces the learning rate when a metric has stopped improving, in this case the validation accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YEQ0Q6Ui6NP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d36c93-71bc-4321-c7d9-e71df1b08fcd"
      },
      "source": [
        "file_path = \"/content/drive/MyDrive/baseline_model.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
        "\n",
        "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.1, patience=20, verbose=1)\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_on_plateau]\n",
        "\n",
        "model = baseline_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
            "94699520/94694792 [==============================] - 2s 0us/step\n",
            "94707712/94694792 [==============================] - 2s 0us/step\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/kernel:0' shape=(7, 7, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_1), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/kernel:0' shape=(1, 1, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_1), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_2), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_2), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_3), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_4), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_3), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_4), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_5), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_5), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_6), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_6), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_7), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_7), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_8), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_8), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_9), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_9), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_10), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_10), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_11), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/kernel:0' shape=(1, 1, 256, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_11), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_12), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_12), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_13), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/kernel:0' shape=(1, 1, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_14), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_13), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_14), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_15), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_15), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_16), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_16), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_17), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_17), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_18), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_18), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_19), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_19), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_20), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_20), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_21), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_21), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_22), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_22), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_23), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_23), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_24), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/kernel:0' shape=(1, 1, 512, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_24), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_25), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_25), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_26), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/kernel:0' shape=(1, 1, 512, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_27), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_26), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_27), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_28), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_28), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_29), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_29), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_30), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_30), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_31), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_31), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_32), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_32), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_33), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_33), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_34), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_34), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_35), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_35), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_36), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_36), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_37), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_37), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_38), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_38), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_39), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_39), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_40), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_40), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_41), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_41), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_42), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_42), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_43), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/kernel:0' shape=(1, 1, 1024, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_43), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_44), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_44), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_45), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/kernel:0' shape=(1, 1, 1024, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_46), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_45), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_46), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_47), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_47), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_48), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_48), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_49), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_49), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_50), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_50), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_51), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_51), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_52), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_52), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_53), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/kernel:0' shape=(7, 7, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_53), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_54), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/kernel:0' shape=(1, 1, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_54), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_55), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_55), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_56), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_57), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_56), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_57), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_58), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_58), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_59), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_59), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_60), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_60), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_61), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_61), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_62), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_62), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_63), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_63), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_64), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/kernel:0' shape=(1, 1, 256, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_64), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_65), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_65), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_66), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/kernel:0' shape=(1, 1, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_67), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_66), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_67), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_68), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_68), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_69), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_69), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_70), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_70), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_71), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_71), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_72), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_72), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_73), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_73), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_74), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_74), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_75), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_75), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_76), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_76), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_77), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/kernel:0' shape=(1, 1, 512, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_77), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_78), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_78), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_79), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/kernel:0' shape=(1, 1, 512, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_80), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_79), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_80), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_81), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_81), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_82), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_82), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_83), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_83), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_84), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_84), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_85), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_85), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_86), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_86), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_87), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_87), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_88), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_88), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_89), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_89), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_90), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_90), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_91), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_91), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_92), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_92), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_93), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_93), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_94), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_94), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_95), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_95), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_96), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/kernel:0' shape=(1, 1, 1024, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_96), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_97), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_97), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_98), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/kernel:0' shape=(1, 1, 1024, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_99), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_98), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_99), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_100), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_100), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_101), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_101), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_102), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_102), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_103), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_103), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_104), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_104), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_105), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_105), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution (TFOpLambda)  (None, 112, 112, 64) 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_53 (TFOpLambd (None, 112, 112, 64) 0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 112, 112, 64 0           tf.nn.convolution[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 112, 112, 64 0           tf.nn.convolution_53[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu (TFOpLambda)         (None, 112, 112, 64) 0           tf.compat.v1.nn.fused_batch_norm[\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_49 (TFOpLambda)      (None, 112, 112, 64) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool (TFOpL (None, 55, 55, 64)   0           tf.nn.relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_1 (TFO (None, 55, 55, 64)   0           tf.nn.relu_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_1 (TFOpLambda (None, 55, 55, 64)   0           tf.compat.v1.nn.max_pool[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_54 (TFOpLambd (None, 55, 55, 64)   0           tf.compat.v1.nn.max_pool_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_54[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_1 (TFOpLambda)       (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_50 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_2 (TFOpLambda (None, 55, 55, 64)   0           tf.nn.relu_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_55 (TFOpLambd (None, 55, 55, 64)   0           tf.nn.relu_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_55[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_2 (TFOpLambda)       (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_51 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_4 (TFOpLambda (None, 55, 55, 256)  0           tf.nn.relu_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_3 (TFOpLambda (None, 55, 55, 256)  0           tf.compat.v1.nn.max_pool[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_57 (TFOpLambd (None, 55, 55, 256)  0           tf.nn.relu_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_56 (TFOpLambd (None, 55, 55, 256)  0           tf.compat.v1.nn.max_pool_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_57[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_56[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_16 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_3 (TFOpLambda)       (None, 55, 55, 256)  0           tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_52 (TFOpLambda)      (None, 55, 55, 256)  0           tf.__operators__.add_16[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_5 (TFOpLambda (None, 55, 55, 64)   0           tf.nn.relu_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_58 (TFOpLambd (None, 55, 55, 64)   0           tf.nn.relu_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_58[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_4 (TFOpLambda)       (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_53 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_6 (TFOpLambda (None, 55, 55, 64)   0           tf.nn.relu_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_59 (TFOpLambd (None, 55, 55, 64)   0           tf.nn.relu_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_59[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_5 (TFOpLambda)       (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_54 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_7 (TFOpLambda (None, 55, 55, 256)  0           tf.nn.relu_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_60 (TFOpLambd (None, 55, 55, 256)  0           tf.nn.relu_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_60[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_17 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_6 (TFOpLambda)       (None, 55, 55, 256)  0           tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_55 (TFOpLambda)      (None, 55, 55, 256)  0           tf.__operators__.add_17[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_8 (TFOpLambda (None, 55, 55, 64)   0           tf.nn.relu_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_61 (TFOpLambd (None, 55, 55, 64)   0           tf.nn.relu_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_61[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_7 (TFOpLambda)       (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_56 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_9 (TFOpLambda (None, 55, 55, 64)   0           tf.nn.relu_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_62 (TFOpLambd (None, 55, 55, 64)   0           tf.nn.relu_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_62[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_8 (TFOpLambda)       (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_57 (TFOpLambda)      (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_10 (TFOpLambd (None, 55, 55, 256)  0           tf.nn.relu_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_63 (TFOpLambd (None, 55, 55, 256)  0           tf.nn.relu_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_63[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_18 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_9 (TFOpLambda)       (None, 55, 55, 256)  0           tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_58 (TFOpLambda)      (None, 55, 55, 256)  0           tf.__operators__.add_18[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_11 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_64 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_64[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_10 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_59 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_12 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_65 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_65[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_11 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_60 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_14 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_13 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_67 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_66 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_67[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_66[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_19 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_12 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_61 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_19[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_15 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_68 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_68[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_13 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_62 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_16 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_69 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_69[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_14 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_63 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_17 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_70 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_70[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_4 (TFOpLam (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_20 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_15 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_64 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_20[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_18 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_71 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_18[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_71[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_16 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_65 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_19 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_72 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_19[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_72[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_17 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_66 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_20 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_73 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_73[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_5 (TFOpLam (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_21 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_18 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_5[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_67 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_21[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_21 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_74 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_21[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_74[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_19 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_68 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_22 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_75 (TFOpLambd (None, 28, 28, 128)  0           tf.nn.relu_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_22[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_75[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_20 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_69 (TFOpLambda)      (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_23 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_76 (TFOpLambd (None, 28, 28, 512)  0           tf.nn.relu_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_76[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_6 (TFOpLam (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_22 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_21 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_6[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_70 (TFOpLambda)      (None, 28, 28, 512)  0           tf.__operators__.add_22[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_24 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_77 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_77[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_22 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_71 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_25 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_78 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_78[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_23 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_72 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_27 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_26 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_80 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_79 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_80[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_79[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_7 (TFOpLam (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_23 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_24 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_7[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_73 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_23[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_28 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_81 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_28[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_81[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_25 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_74 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_29 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_82 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_29[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_82[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_26 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_75 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_30 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_83 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_30[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_83[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_8 (TFOpLam (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_24 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_27 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_8[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_76 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_24[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_31 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_84 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_31[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_84[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_28 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_77 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_32 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_85 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_32[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_85[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_29 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_78 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_33 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_86 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_33[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_86[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_9 (TFOpLam (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_25 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_76[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_30 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_9[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_79 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_25[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_34 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_87 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_34[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_87[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_31 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_80 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_35 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_88 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_35[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_88[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_32 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_81 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_36 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_89 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_36[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_89[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_10 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_26 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_33 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_10[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_82 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_26[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_37 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_90 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_37[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_90[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_34 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_83 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_38 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_91 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_38[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_91[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_35 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_84 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_39 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_92 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_39[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_92[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_11 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_27 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_36 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_11[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_85 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_27[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_40 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_93 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_40[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_93[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_37 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_86 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_41 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_94 (TFOpLambd (None, 14, 14, 256)  0           tf.nn.relu_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_41[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_94[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_38 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_87 (TFOpLambda)      (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_42 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_95 (TFOpLambd (None, 14, 14, 1024) 0           tf.nn.relu_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_42[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_95[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_12 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_28 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_39 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_12[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_88 (TFOpLambda)      (None, 14, 14, 1024) 0           tf.__operators__.add_28[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_43 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_96 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_43[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_96[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_40 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_89 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_44 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_97 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_44[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_97[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_41 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_90 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_46 (TFOpLambd (None, 7, 7, 2048)   0           tf.nn.relu_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_45 (TFOpLambd (None, 7, 7, 2048)   0           tf.nn.relu_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_99 (TFOpLambd (None, 7, 7, 2048)   0           tf.nn.relu_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_98 (TFOpLambd (None, 7, 7, 2048)   0           tf.nn.relu_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_46[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_45[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_99[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_98[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_13 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_29 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_42 (TFOpLambda)      (None, 7, 7, 2048)   0           tf.__operators__.add_13[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_91 (TFOpLambda)      (None, 7, 7, 2048)   0           tf.__operators__.add_29[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_47 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_100 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_47[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_100[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_43 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_92 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_48 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_101 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_48[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_101[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_44 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_93 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_49 (TFOpLambd (None, 7, 7, 2048)   0           tf.nn.relu_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_102 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_49[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_102[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_14 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_30 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_45 (TFOpLambda)      (None, 7, 7, 2048)   0           tf.__operators__.add_14[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_94 (TFOpLambda)      (None, 7, 7, 2048)   0           tf.__operators__.add_30[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_50 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_103 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_50[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_103[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_46 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_95 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_51 (TFOpLambd (None, 7, 7, 512)    0           tf.nn.relu_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_104 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_51[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_104[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_47 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_96 (TFOpLambda)      (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_52 (TFOpLambd (None, 7, 7, 2048)   0           tf.nn.relu_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_105 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_52[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_105[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_15 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_31 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_48 (TFOpLambda)      (None, 7, 7, 2048)   0           tf.__operators__.add_15[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_97 (TFOpLambda)      (None, 7, 7, 2048)   0           tf.__operators__.add_31[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.avg_pool (TFOpL (None, 1, 1, 2048)   0           tf.nn.relu_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.avg_pool_1 (TFO (None, 1, 1, 2048)   0           tf.nn.relu_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d (GlobalMax (None, 2048)         0           tf.compat.v1.nn.avg_pool[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           tf.compat.v1.nn.avg_pool[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_1 (GlobalM (None, 2048)         0           tf.compat.v1.nn.avg_pool_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           tf.compat.v1.nn.avg_pool_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4096)         0           global_max_pooling2d[0][0]       \n",
            "                                                                 global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 4096)         0           global_max_pooling2d_1[0][0]     \n",
            "                                                                 global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "subtract (Subtract)             (None, 4096)         0           concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 4096)         0           concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply (Multiply)             (None, 4096)         0           subtract[0][0]                   \n",
            "                                                                 subtract[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8192)         0           multiply_1[0][0]                 \n",
            "                                                                 multiply[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          819300      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 100)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            101         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 819,401\n",
            "Trainable params: 819,401\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDQn3ZdZAnX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85380884-6485-4832-ce85-b5177b167552"
      },
      "source": [
        "model.fit(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=False,\n",
        "                validation_data=gen(val, val_person_to_images_map, batch_size=16), epochs=25, verbose=1,\n",
        "                workers=1, callbacks=callbacks_list, steps_per_epoch=100, validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "100/100 [==============================] - 646s 6s/step - loss: 8.0483 - acc: 0.5931 - val_loss: 10.8073 - val_acc: 0.4025\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.40250, saving model to /content/drive/MyDrive/baseline_model.h5\n",
            "Epoch 2/25\n",
            "100/100 [==============================] - 261s 3s/step - loss: 3.9958 - acc: 0.7106 - val_loss: 7.2005 - val_acc: 0.5487\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.40250 to 0.54875, saving model to /content/drive/MyDrive/baseline_model.h5\n",
            "Epoch 3/25\n",
            "100/100 [==============================] - 164s 2s/step - loss: 2.6904 - acc: 0.7713 - val_loss: 6.9093 - val_acc: 0.5500\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.54875 to 0.55000, saving model to /content/drive/MyDrive/baseline_model.h5\n",
            "Epoch 4/25\n",
            "100/100 [==============================] - 101s 1s/step - loss: 1.7861 - acc: 0.8263 - val_loss: 6.8853 - val_acc: 0.5362\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.55000\n",
            "Epoch 5/25\n",
            "100/100 [==============================] - 76s 768ms/step - loss: 1.4703 - acc: 0.8569 - val_loss: 6.2384 - val_acc: 0.5950\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.55000 to 0.59500, saving model to /content/drive/MyDrive/baseline_model.h5\n",
            "Epoch 6/25\n",
            "100/100 [==============================] - 61s 618ms/step - loss: 1.0498 - acc: 0.8925 - val_loss: 6.1109 - val_acc: 0.6225\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.59500 to 0.62250, saving model to /content/drive/MyDrive/baseline_model.h5\n",
            "Epoch 7/25\n",
            "100/100 [==============================] - 52s 523ms/step - loss: 0.8706 - acc: 0.8994 - val_loss: 5.9244 - val_acc: 0.6662\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.62250 to 0.66625, saving model to /content/drive/MyDrive/baseline_model.h5\n",
            "Epoch 8/25\n",
            "100/100 [==============================] - 40s 401ms/step - loss: 0.8007 - acc: 0.9044 - val_loss: 8.0380 - val_acc: 0.5838\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.66625\n",
            "Epoch 9/25\n",
            "100/100 [==============================] - 40s 400ms/step - loss: 0.5399 - acc: 0.9287 - val_loss: 7.1404 - val_acc: 0.6425\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.66625\n",
            "Epoch 10/25\n",
            "100/100 [==============================] - 32s 324ms/step - loss: 0.5006 - acc: 0.9388 - val_loss: 7.1239 - val_acc: 0.6225\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.66625\n",
            "Epoch 11/25\n",
            "100/100 [==============================] - 32s 319ms/step - loss: 0.4202 - acc: 0.9450 - val_loss: 7.6273 - val_acc: 0.6325\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.66625\n",
            "Epoch 12/25\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.4452 - acc: 0.9444 - val_loss: 8.6108 - val_acc: 0.6225\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.66625\n",
            "Epoch 13/25\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.3313 - acc: 0.9531 - val_loss: 7.7893 - val_acc: 0.6388\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.66625\n",
            "Epoch 14/25\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.3508 - acc: 0.9538 - val_loss: 7.0821 - val_acc: 0.6700\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.66625 to 0.67000, saving model to /content/drive/MyDrive/baseline_model.h5\n",
            "Epoch 15/25\n",
            "100/100 [==============================] - 25s 253ms/step - loss: 0.3322 - acc: 0.9638 - val_loss: 8.1222 - val_acc: 0.6350\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.67000\n",
            "Epoch 16/25\n",
            "100/100 [==============================] - 24s 239ms/step - loss: 0.3010 - acc: 0.9581 - val_loss: 8.1571 - val_acc: 0.6225\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.67000\n",
            "Epoch 17/25\n",
            "100/100 [==============================] - 23s 232ms/step - loss: 0.2200 - acc: 0.9688 - val_loss: 8.5939 - val_acc: 0.6350\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.67000\n",
            "Epoch 18/25\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.2665 - acc: 0.9688 - val_loss: 8.5234 - val_acc: 0.6313\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.67000\n",
            "Epoch 19/25\n",
            "100/100 [==============================] - 23s 231ms/step - loss: 0.1707 - acc: 0.9737 - val_loss: 9.1766 - val_acc: 0.6650\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.67000\n",
            "Epoch 20/25\n",
            "100/100 [==============================] - 24s 238ms/step - loss: 0.2262 - acc: 0.9669 - val_loss: 8.9828 - val_acc: 0.6363\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.67000\n",
            "Epoch 21/25\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.2011 - acc: 0.9675 - val_loss: 8.4475 - val_acc: 0.6413\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.67000\n",
            "Epoch 22/25\n",
            "100/100 [==============================] - 21s 210ms/step - loss: 0.1533 - acc: 0.9775 - val_loss: 7.9588 - val_acc: 0.6475\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.67000\n",
            "Epoch 23/25\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.1352 - acc: 0.9787 - val_loss: 8.5965 - val_acc: 0.6562\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.67000\n",
            "Epoch 24/25\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.1689 - acc: 0.9819 - val_loss: 9.4148 - val_acc: 0.6637\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.67000\n",
            "Epoch 25/25\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.1708 - acc: 0.9781 - val_loss: 9.2120 - val_acc: 0.6338\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.67000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4e7e2e8bd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIl075HvEfAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40edfbb-c133-4d7b-8eff-0ad2068088ed"
      },
      "source": [
        "# Modify paths as per your need\n",
        "test_path = \"/content/drive/MyDrive/Kinship Recognition Starter/test/\"\n",
        "\n",
        "model = baseline_model()\n",
        "model.load_weights(\"/content/drive/MyDrive/baseline_model.h5\")\n",
        "\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Kinship Recognition Starter/test_ds.csv')\n",
        "predictions = []\n",
        "\n",
        "for i in range(0, len(submission.p1.values), 32):\n",
        "    X1 = submission.p1.values[i:i+32]\n",
        "    X1 = np.array([read_img(test_path + x) for x in X1])\n",
        "\n",
        "    X2 = submission.p2.values[i:i+32]\n",
        "    X2 = np.array([read_img(test_path + x) for x in X2])\n",
        "\n",
        "    pred = model.predict([X1, X2]).ravel().tolist()\n",
        "    predictions += pred"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_212), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/kernel:0' shape=(7, 7, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_212), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_213), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/kernel:0' shape=(1, 1, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_213), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_214), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_214), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_215), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_216), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_215), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_216), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_217), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_217), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_218), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_218), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_219), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_219), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_220), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_220), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_221), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_221), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_222), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_222), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_223), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/kernel:0' shape=(1, 1, 256, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_223), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_224), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_224), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_225), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/kernel:0' shape=(1, 1, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_226), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_225), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_226), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_227), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_227), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_228), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_228), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_229), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_229), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_230), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_230), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_231), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_231), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_232), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_232), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_233), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_233), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_234), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_234), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_235), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_235), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_236), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/kernel:0' shape=(1, 1, 512, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_236), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_237), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_237), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_238), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/kernel:0' shape=(1, 1, 512, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_239), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_238), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_239), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_240), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_240), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_241), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_241), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_242), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_242), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_243), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_243), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_244), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_244), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_245), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_245), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_246), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_246), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_247), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_247), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_248), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_248), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_249), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_249), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_250), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_250), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_251), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_251), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_252), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_252), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_253), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_253), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_254), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_254), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_255), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/kernel:0' shape=(1, 1, 1024, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_255), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_256), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_256), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_257), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/kernel:0' shape=(1, 1, 1024, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_258), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_257), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_258), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_259), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_259), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_260), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_260), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_261), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_261), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_262), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_262), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_263), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_263), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_264), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_264), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_265), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/kernel:0' shape=(7, 7, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_265), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_266), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/kernel:0' shape=(1, 1, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_266), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_267), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_267), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_268), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_269), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_268), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_269), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_270), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_270), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_271), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_271), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_272), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_272), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_273), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_273), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_274), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_274), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_275), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_275), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_276), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/kernel:0' shape=(1, 1, 256, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_276), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_277), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_277), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_278), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/kernel:0' shape=(1, 1, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_279), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_278), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_279), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_280), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_280), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_281), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_281), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_282), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_282), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_283), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_283), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_284), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_284), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_285), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_285), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_286), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_286), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_287), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_287), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_288), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_288), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_289), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/kernel:0' shape=(1, 1, 512, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_289), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_290), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_290), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_291), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/kernel:0' shape=(1, 1, 512, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_292), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_291), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_292), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_293), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_293), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_294), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_294), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_295), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_295), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_296), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_296), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_297), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_297), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_298), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_298), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_299), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_299), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_300), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_300), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_301), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_301), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_302), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_302), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_303), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_303), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_304), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_304), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_305), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_305), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_306), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_306), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_307), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_307), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_308), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/kernel:0' shape=(1, 1, 1024, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_308), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_309), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_309), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_310), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/kernel:0' shape=(1, 1, 1024, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_311), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_310), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_311), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_312), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_312), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_313), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_313), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_314), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_314), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_315), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_315), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_316), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_316), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_317), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_317), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_212 (TFOpLamb (None, 112, 112, 64) 0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_265 (TFOpLamb (None, 112, 112, 64) 0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 112, 112, 64 0           tf.nn.convolution_212[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 112, 112, 64 0           tf.nn.convolution_265[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_196 (TFOpLambda)     (None, 112, 112, 64) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_245 (TFOpLambda)     (None, 112, 112, 64) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_4 (TFO (None, 55, 55, 64)   0           tf.nn.relu_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_5 (TFO (None, 55, 55, 64)   0           tf.nn.relu_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_213 (TFOpLamb (None, 55, 55, 64)   0           tf.compat.v1.nn.max_pool_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_266 (TFOpLamb (None, 55, 55, 64)   0           tf.compat.v1.nn.max_pool_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_213[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_266[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_197 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_246 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_214 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_267 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_214[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_267[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_198 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_247 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_216 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_215 (TFOpLamb (None, 55, 55, 256)  0           tf.compat.v1.nn.max_pool_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_269 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_268 (TFOpLamb (None, 55, 55, 256)  0           tf.compat.v1.nn.max_pool_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_216[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_215[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_269[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_268[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_64 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_80 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_199 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_64[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_248 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_80[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_217 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_270 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_217[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_270[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_200 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_249 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_218 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_271 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_218[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_271[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_201 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_250 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_219 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_272 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_219[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_272[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_65 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_81 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_202 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_65[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_251 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_81[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_220 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_273 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_220[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_273[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_203 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_252 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_221 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_274 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_221[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_274[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_204 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_253 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_222 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_275 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_222[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_275[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_66 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_82 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_205 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_66[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_254 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_82[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_223 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_276 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_223[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_276[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_206 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_255 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_224 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_277 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_224[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_277[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_207 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_256 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_226 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_225 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_279 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_278 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_226[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_225[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_279[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_278[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_67 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_83 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_208 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_67[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_257 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_83[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_227 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_280 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_227[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_280[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_209 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_258 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_228 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_281 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_228[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_281[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_210 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_259 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_229 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_282 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_229[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_282[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_68 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_84 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_211 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_68[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_260 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_84[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_230 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_283 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_230[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_283[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_212 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_261 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_231 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_212[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_284 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_231[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_284[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_213 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_262 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_232 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_285 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_232[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_285[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_69 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_85 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_214 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_69[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_263 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_85[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_233 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_286 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_233[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_286[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_215 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_264 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_234 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_287 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_234[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_287[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_216 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_265 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_235 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_288 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_235[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_288[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_70 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_86 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_217 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_70[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_266 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_86[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_236 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_289 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_236[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_289[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_218 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_267 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_237 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_290 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_237[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_290[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_219 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_268 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_239 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_238 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_292 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_291 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_239[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_238[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_292[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_291[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_71 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_87 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_220 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_71[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_269 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_87[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_240 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_293 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_240[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_293[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_221 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_270 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_241 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_221[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_294 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_270[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_241[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_294[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_222 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_271 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_242 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_295 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_242[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_295[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_72 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_88 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_223 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_72[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_272 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_88[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_243 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_296 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_243[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_296[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_224 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_273 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_244 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_297 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_244[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_297[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_225 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_274 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_245 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_298 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_245[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_298[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_73 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_89 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_226 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_73[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_275 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_89[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_246 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_299 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_246[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_299[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_227 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_276 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_247 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_300 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_247[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_300[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_228 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_277 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_248 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_301 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_248[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_301[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_74 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_90 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_229 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_74[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_278 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_90[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_249 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_302 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_249[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_302[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_230 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_279 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_250 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_303 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_250[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_303[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_231 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_280 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_251 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_304 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_251[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_304[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_75 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_91 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_232 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_75[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_281 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_91[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_252 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_305 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_252[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_305[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_233 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_282 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_253 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_306 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_253[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_306[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_234 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_283 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_254 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_307 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_254[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_307[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_76 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_92 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_235 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_76[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_284 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_92[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_255 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_308 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_255[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_308[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_236 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_285 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_256 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_236[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_309 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_256[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_309[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_237 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_286 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_258 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_257 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_311 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_310 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_258[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_257[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_311[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_310[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_77 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_93 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_238 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_77[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_287 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_93[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_259 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_312 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_259[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_312[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_239 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_288 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_260 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_313 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_260[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_313[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_240 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_289 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_261 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_314 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_261[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_314[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_78 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_94 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_241 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_78[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_290 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_94[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_262 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_315 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_262[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_315[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_242 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_291 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_263 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_316 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_263[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_316[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_243 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_292 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_264 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_317 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_264[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_317[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_79 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_95 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_244 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_79[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_293 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_95[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.avg_pool_4 (TFO (None, 1, 1, 2048)   0           tf.nn.relu_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.avg_pool_5 (TFO (None, 1, 1, 2048)   0           tf.nn.relu_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_4 (GlobalM (None, 2048)         0           tf.compat.v1.nn.avg_pool_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 2048)         0           tf.compat.v1.nn.avg_pool_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_5 (GlobalM (None, 2048)         0           tf.compat.v1.nn.avg_pool_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_5 (Glo (None, 2048)         0           tf.compat.v1.nn.avg_pool_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 4096)         0           global_max_pooling2d_4[0][0]     \n",
            "                                                                 global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 4096)         0           global_max_pooling2d_5[0][0]     \n",
            "                                                                 global_average_pooling2d_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "subtract_2 (Subtract)           (None, 4096)         0           concatenate_6[0][0]              \n",
            "                                                                 concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_5 (Multiply)           (None, 4096)         0           concatenate_6[0][0]              \n",
            "                                                                 concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, 4096)         0           subtract_2[0][0]                 \n",
            "                                                                 subtract_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 8192)         0           multiply_5[0][0]                 \n",
            "                                                                 multiply_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 100)          819300      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 100)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            101         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 819,401\n",
            "Trainable params: 819,401\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXyzufq7iZ1g"
      },
      "source": [
        "The final predictions will need to be rounded: EG 0.01 rounded to 0 and 0.78 rounded to 1. The simple .round() function is sufficient as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkFEH-uva9c_"
      },
      "source": [
        "d = {'index': np.arange(0, 3000, 1), 'label':predictions}\n",
        "submissionfile = pd.DataFrame(data=d)\n",
        "submissionfile = submissionfile.round()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EbbawPYrchP"
      },
      "source": [
        "submissionfile.to_csv(\"/content/drive/MyDrive/kinship_test/c.wilkerson_ksc2138.csv\", index=False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhmkS9DKxFrt"
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.read_csv(\"/content/drive/MyDrive/kinship_test/cw3329_ksc2138.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp_0Mkvwxt1R"
      },
      "source": [
        "df.astype('int64').to_csv(\"/content/drive/MyDrive/kinship_test/cw3329_ksc2138.csv\", index=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNodVS9W4NMB"
      },
      "source": [
        "At this point, download the CSV and submit it on Kaggle to score your predictions.\n"
      ]
    }
  ]
}