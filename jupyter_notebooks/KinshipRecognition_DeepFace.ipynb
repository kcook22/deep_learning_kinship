{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Kinship_Recognition_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4g8yMLqtS3W"
      },
      "source": [
        "# **Large-Scale Kinship Recognition Data Challenge: Kinship Verification STARTER NOTEBOOK**\n",
        "\n",
        "We provide framework code to get you started on the competition. The notebook is broken up into three main sections. \n",
        "1. Data Loading & Visualizing\n",
        "2. Data Generator & Model Building\n",
        "3. Training & Testing Model\n",
        "\n",
        "We have done the majority of the heavy lifting by making the data easily and readily accessible through Google Drive. Furthermore, we have made the task easier by creating a dataloader and fully trained end-to-end model that predicts a binary label (0 or 1) denoting whether two faces share a kinship relation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjYhbL1xxgfU",
        "outputId": "a7143492-30e3-4bc5-83c7-416d8396e26b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LDDgTAe2w0H"
      },
      "source": [
        "**WARNING: IF YOU HAVE NOT DONE SO**\n",
        "\n",
        "Change to GPU:\n",
        "\n",
        "Runtime --> Change Runtime Type --> GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWf8L2-Ru6ZE"
      },
      "source": [
        "Mount to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ribPmcZau-vR"
      },
      "source": [
        "Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS3ZhSjIAGgt"
      },
      "source": [
        "%%capture\n",
        "!pip install keras_vggface\n",
        "!pip install keras_applications\n",
        "!pip install arcface\n",
        "!pip install deepface"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4yFxckrAAZx"
      },
      "source": [
        "from collections import defaultdict\n",
        "from glob import glob\n",
        "from random import choice, sample\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.vggface import VGGFace\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF0H95sMQb9t",
        "outputId": "79f12782-2512-4b2b-883a-e144c96cb4a8"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXViO7APvFYW"
      },
      "source": [
        "train_relationships.csv contains pairs of image paths which are positive samples (related to each other).\n",
        "\n",
        "train-faces contains the images for training itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItZNSTCVAESV"
      },
      "source": [
        "# Modify paths as per your method of saving them\n",
        "train_file_path = \"/content/drive/MyDrive/Kinship Recognition Starter/train_ds.csv\"\n",
        "train_folders_path = \"/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/\"\n",
        "# All images belonging to families F09** will be used to create the validation set while training the model\n",
        "# For final submission, you can add these to the training data as well\n",
        "val_famillies = \"F09\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLuyuKKBAWMf"
      },
      "source": [
        "all_images = glob(train_folders_path + \"*/*/*.jpg\")\n",
        "\n",
        "train_images = [x for x in all_images if val_famillies not in x]\n",
        "val_images = [x for x in all_images if val_famillies in x]\n",
        "\n",
        "train_person_to_images_map = defaultdict(list)\n",
        "\n",
        "ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in all_images]\n",
        "\n",
        "for x in train_images:\n",
        "    train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
        "\n",
        "val_person_to_images_map = defaultdict(list)\n",
        "\n",
        "for x in val_images:\n",
        "    val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HQExgwH95NU",
        "outputId": "327cc6b6-ac16-47cf-fbd1-458bbbad00ac"
      },
      "source": [
        "all_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03496_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03500_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03497_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03501_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03492_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03499_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03494_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03493_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03495_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID1/P03498_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03496_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03500_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03494_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03498_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID3/P03495_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID4/P03501_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID4/P03494_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID4/P03495_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID5/P03500_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID5/P03497_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID5/P03498_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID2/P03499_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID2/P03492_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0330/MID2/P03493_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09897_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09901_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09900_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09896_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09903_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09895_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09902_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID1/P09899_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09897_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09901_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09900_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09903_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09898_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09902_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID3/P09904_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID4/P09900_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID4/P09898_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID4/P09904_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID4/P09902_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09901_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09897_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09896_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09895_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09898_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09904_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0939/MID2/P09899_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05980_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05977_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05971_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05981_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05973_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05982_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05978_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05975_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05983_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05972_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05979_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID1/P05974_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05971_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05982_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05973_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05975_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID3/P05972_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05971_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05980_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05977_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05975_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05978_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05972_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05974_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID4/P05979_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05980_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05971_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05977_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05975_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05978_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05972_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID5/P05974_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05971_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05981_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05973_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05983_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0568/MID2/P05972_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09805_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09811_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09809_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09810_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09813_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09814_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09806_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID1/P09812_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID6/P09809_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID3/P09808_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID3/P09813_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID3/P09807_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID4/P09811_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID4/P09809_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID4/P09812_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID5/P09809_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID5/P09812_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09808_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09805_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09810_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09809_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09807_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09813_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09812_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09814_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0930/MID2/P09806_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID7/P08334_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID8/P08336_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID1/P08334_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID1/P08337_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID1/P08336_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID1/P08341_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID6/P08334_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID3/P08333_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID3/P08334_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID3/P08341_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID4/P08334_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID4/P08341_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID5/P08333_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID5/P08334_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID2/P08337_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0791/MID2/P08336_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01390_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09130_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09129_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01396_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09125_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09131_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09128_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01397_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01392_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09126_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01399_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01394_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01393_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P09127_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01398_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID1/P01395_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01389_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01390_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09130_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01396_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09125_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01397_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09134_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01399_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P01394_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09132_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID3/P09133_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID4/P01397_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID4/P01398_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID5/P01398_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P01389_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P09125_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P09132_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P01393_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0133/MID2/P01395_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID7/P07713_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID9/P07717_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID8/P07717_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07712_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07714_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07713_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07715_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07710_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07716_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07708_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID1/P07711_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID6/P07713_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07712_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07714_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07710_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07709_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07716_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07708_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07711_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID3/P07717_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07712_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07714_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07715_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07709_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07710_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID4/P07711_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID5/P07713_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07712_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07714_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07709_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07710_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07716_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0736/MID2/P07708_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07415_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07434_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07432_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07426_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07414_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07427_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07433_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07430_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07429_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07417_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07416_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07431_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID1/P07428_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID3/P07415_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID3/P07414_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID3/P07416_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID4/P07415_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID4/P07414_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID4/P07417_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID4/P07416_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07415_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07426_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07432_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07414_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07433_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07427_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07429_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07416_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07431_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0709/MID2/P07428_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04205_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04208_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04211_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04210_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04204_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04207_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04213_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04206_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID1/P04212_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04208_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04211_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04210_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04209_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04213_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID3/P04212_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04205_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04208_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04204_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04209_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04207_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04213_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04206_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0399/MID2/P04212_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01792_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01794_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01793_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01795_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01803_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01796_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID1/P01804_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID3/P01795_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID3/P01804_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID4/P01797_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01792_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01794_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01793_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01795_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0167/MID2/P01796_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID7/P07666_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID7/P07665_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07658_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07666_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07663_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07665_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07662_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID1/P07664_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID6/P07666_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID6/P07665_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID5/P07663_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID5/P07662_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID5/P07664_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID2/P07658_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID2/P07662_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0731/MID2/P07664_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10437_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10437_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10429_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10429_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10435_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10435_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10433_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID7/P10433_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10437_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10437_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10429_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10429_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10435_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10433_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10435_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10433_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10437_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10437_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10429_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10429_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10433_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10433_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10435_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID8/P10435_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10428_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10432_face9.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10431_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10431_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10428_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10430_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10436_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10430_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P06405_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P06405_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P06410_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID1/P10432_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10432_face8.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10437_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10437_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10429_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10436_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10429_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10433_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10433_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10435_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID6/P10432_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID11/P10432_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID11/P10432_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10428_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10431_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10428_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06401_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10431_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06403_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06403_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06409_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06404_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P06409_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10434_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10434_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10431_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06401_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10428_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10428_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06401_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10431_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10436_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10436_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06403_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06403_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06404_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06409_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P06409_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID3/P10434_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10428_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10431_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10437_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10431_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10429_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10429_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10436_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10435_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10433_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10433_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10432_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID4/P10432_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10431_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10437_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10437_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10428_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10431_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10429_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10429_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10436_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10433_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10433_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10435_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10432_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID5/P10432_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID2/P10436_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID2/P10430_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10431_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10428_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10431_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10428_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10430_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID12/P10430_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID13/P10430_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID13/P10430_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID14/P10430_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID7/P10557_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID1/P10551_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID1/P10554_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID1/P10552_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID1/P10553_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID6/P10556_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID6/P10555_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID3/P10551_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID3/P10553_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID4/P10552_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID4/P10558_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID5/P10560_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID5/P10553_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID2/P10551_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0999/MID2/P10559_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID7/P04136_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID8/P04136_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04131_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04137_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04129_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04130_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04136_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04127_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04138_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04132_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID1/P04134_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID6/P04127_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID6/P04132_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID3/P04131_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID3/P04129_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID4/P04137_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID4/P04127_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID4/P04132_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID4/P04134_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID5/P04138_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID5/P04127_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID5/P04132_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID5/P04134_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID2/P04131_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID2/P04129_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0390/MID2/P04130_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID1/P01819_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID1/P01817_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID1/P01816_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID3/P01816_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID4/P01819_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID2/P01817_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0169/MID2/P01816_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08436_face11.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08417_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08430_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08416_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08437_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08431_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08410_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08415_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08418_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08434_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08432_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08413_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08419_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08438_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08412_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID1/P08411_face8.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID3/P08441_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID3/P08437_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID3/P08410_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID3/P08442_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08417_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08440_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08439_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08418_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID4/P08412_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08417_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08411_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08436_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08430_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08437_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08416_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08431_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08418_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08434_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08415_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08413_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08432_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0797/MID2/P08438_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09817_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09824_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09823_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09816_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09818_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09815_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09820_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID1/P09819_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09817_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09822_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09824_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09823_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09818_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09820_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID3/P09819_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID4/P09824_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID4/P09821_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0931/MID2/P09815_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID1/P12238_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID1/P12239_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID1/P12237_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12249_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12248_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12245_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12246_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID6/P12247_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID3/P12242_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID3/P12243_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID4/P12243_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID5/P12244_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID5/P12243_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12242_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12243_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12245_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12240_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12246_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0309/MID2/P12241_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09576_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09581_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09577_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09580_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09579_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09583_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09575_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09578_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09582_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID1/P09584_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09576_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09577_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09583_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09578_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09575_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID3/P09584_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09581_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09577_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09580_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09579_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09575_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0907/MID2/P09582_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID7/P07904_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID7/P07879_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID9/P07904_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID9/P07879_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID8/P07879_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07895_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07905_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07908_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07893_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07880_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07899_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07902_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07886_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07909_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07892_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07883_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07901_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07897_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07885_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07891_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07896_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07878_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID1/P07884_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID6/P07904_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID6/P07879_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID10/P07881_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID10/P07887_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07895_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07887_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07905_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07893_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07881_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07902_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07892_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07880_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07909_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07886_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07894_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07897_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07901_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07883_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07907_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07891_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07896_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07878_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07900_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID3/P07884_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07895_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07898_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07893_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07894_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07899_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07880_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07909_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07892_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07901_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07897_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07907_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07888_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07891_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07900_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07896_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07890_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID4/P07878_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID5/P07878_face8.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07895_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07898_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07908_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07893_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07905_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07880_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07899_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07892_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07909_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07904_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07894_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07901_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07897_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07891_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07879_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07907_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07883_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07896_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07900_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07878_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0752/MID2/P07889_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID7/P07978_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07979_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07975_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07982_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07976_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID1/P07977_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID6/P07982_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID3/P07978_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID3/P07976_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID4/P07977_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID5/P07979_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0755/MID2/P07975_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05615_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05611_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05610_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05609_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID1/P05616_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID3/P05616_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05615_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05611_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05610_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05609_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0534/MID2/P05616_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01700_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01701_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01707_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01699_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01702_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01704_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01698_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01703_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID1/P01705_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01700_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01701_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01707_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01699_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01704_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID3/P01703_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01701_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01702_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01704_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01698_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0159/MID2/P01705_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05338_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05335_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05336_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05330_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID1/P05337_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID6/P05337_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID3/P05330_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID4/P05330_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID2/P05338_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID2/P05335_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID2/P05336_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0505/MID2/P05330_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID7/P04196_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID7/P04201_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID7/P04195_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID8/P04196_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID8/P04195_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04203_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04202_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04197_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04199_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04194_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04201_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04195_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04198_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID1/P04200_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID6/P04201_face8.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04196_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04197_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04199_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04201_face7.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04198_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04200_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID3/P04195_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04196_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04197_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04201_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04195_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID4/P04200_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04196_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04199_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04201_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04200_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID5/P04195_face6.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04203_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04197_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04202_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04201_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04194_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04200_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0398/MID2/P04195_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID1/P10516_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID1/P10522_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID1/P10529_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID3/P10526_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID3/P10516_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID3/P10517_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10519_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10521_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10527_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10518_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10520_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10526_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10528_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID4/P10525_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID5/P10523_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID5/P10524_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID2/P10516_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID2/P10522_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0996/MID2/P10529_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04741_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04736_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04746_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04740_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04745_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04732_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04739_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04744_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04733_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04738_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID1/P04742_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID3/P04733_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04741_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04746_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04740_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04745_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04743_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04744_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID4/P04742_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID5/P04745_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID5/P04744_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04736_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04737_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04732_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04739_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04733_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0448/MID2/P04738_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07195_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07193_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07194_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07192_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07188_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07191_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07196_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07189_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID1/P07190_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID3/P07193_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID3/P07194_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID3/P07192_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID3/P07191_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID4/P07195_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID4/P07194_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID4/P07196_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID2/P07194_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID2/P07188_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID2/P07189_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0689/MID2/P07190_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04956_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04950_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04949_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04957_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04951_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID1/P04953_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID3/P04954_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID3/P04952_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID3/P04953_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID4/P04954_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID4/P04952_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID4/P04955_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID4/P04953_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04956_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04950_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04949_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04957_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04951_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04954_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04952_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0470/MID2/P04955_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02410_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02405_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02411_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02408_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02412_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02414_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02407_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID1/P02413_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID3/P02410_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID3/P02408_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID3/P02412_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID3/P02413_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID4/P02409_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID4/P02411_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID5/P02409_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID5/P02411_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID2/P02410_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID2/P02405_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID2/P02414_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0226/MID2/P02407_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00221_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00227_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00220_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00226_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00223_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00225_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00228_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00222_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00224_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID1/P00229_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID3/P00221_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID3/P00222_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID3/P00229_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID4/P00225_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID4/P00224_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID4/P00229_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID5/P00228_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID2/P00227_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID2/P00220_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID2/P00226_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0022/MID2/P00223_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID7/P04718_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04717_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04720_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04718_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04715_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04719_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04712_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04721_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID1/P04714_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID3/P04712_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID3/P04714_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID3/P04721_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID4/P04720_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID4/P04715_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID4/P04714_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04717_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04712_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04719_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04721_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0446/MID2/P04714_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07041_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07036_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07047_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07040_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07037_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07034_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07039_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07045_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07035_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07038_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07042_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07033_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID1/P07044_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07041_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07036_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07040_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07037_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07039_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07034_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07043_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07045_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07035_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07038_face5.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID3/P07044_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07036_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07041_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07037_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07040_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07046_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07039_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07034_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07038_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID4/P07035_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07041_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07040_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07037_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07039_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07036_face9.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07038_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID5/P07035_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07036_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07041_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07047_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07037_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07040_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07046_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07039_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07043_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07035_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07042_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07033_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0674/MID2/P07038_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08740_face4.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08731_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08737_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08736_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08733_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08735_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08738_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08732_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08739_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID1/P08734_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID3/P08731_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID3/P08735_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID3/P08740_face10.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID3/P08739_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08731_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08737_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08740_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08736_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08733_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08735_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08732_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID4/P08734_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08731_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08736_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08733_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08738_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08735_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08734_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0826/MID2/P08740_face9.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06585_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06579_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06581_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06577_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06586_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID1/P06580_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06583_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06584_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06578_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06582_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID3/P06577_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06579_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06585_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06583_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06578_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06584_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06582_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06581_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06577_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06586_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0627/MID2/P06580_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02577_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02571_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02568_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02569_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02575_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02573_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID1/P02572_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID3/P02577_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID3/P02568_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID3/P02576_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID3/P02569_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID4/P02571_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID4/P02570_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID4/P02574_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID5/P02573_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02577_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02568_face3.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02571_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02576_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02570_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02569_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02575_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02574_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0243/MID2/P02572_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00727_face1.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00719_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00721_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00720_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00728_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00725_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00723_face2.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00729_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00724_face0.jpg',\n",
              " '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0071/MID1/P00722_face3.jpg',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSI5FN3RAXXp"
      },
      "source": [
        "relationships = pd.read_csv(train_file_path)\n",
        "relationships = list(zip(relationships.p1.values, relationships.p2.values, relationships.relationship.values))\n",
        "relationships = [(x[0],x[1],x[2]) for x in relationships if x[0][:10] in ppl and x[1][:10] in ppl]\n",
        "\n",
        "train = [x for x in relationships if val_famillies not in x[0]]\n",
        "val = [x for x in relationships if val_famillies in x[0]]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KfHltcuAZcB"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "def read_img(path):\n",
        "    img = image.load_img(path, target_size=(224, 224))\n",
        "    img = np.array(img).astype(np.float)\n",
        "    return preprocess_input(img, version=2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5k69UJzvb26"
      },
      "source": [
        "Define a data generator. Here our data generator will generate a batch of examples which will be used by our model in training. It will generate two images, one for each in the pair as well as a label associated with it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcAZG7JYAdhY"
      },
      "source": [
        "def gen(list_tuples, person_to_images_map, batch_size=16):\n",
        "    ppl = list(person_to_images_map.keys())\n",
        "    while True:\n",
        "        batch_tuples = sample(list_tuples, batch_size)\n",
        "        \n",
        "        # All the samples are taken from train_ds.csv, labels are in the labels column\n",
        "        labels = []\n",
        "        for tup in batch_tuples:\n",
        "          labels.append(tup[2])\n",
        "\n",
        "        X1 = [x[0] for x in batch_tuples]\n",
        "        X1 = np.array([read_img(train_folders_path + x) for x in X1])\n",
        "\n",
        "        X2 = [x[1] for x in batch_tuples]\n",
        "        X2 = np.array([read_img(train_folders_path + x) for x in X2])\n",
        "\n",
        "        yield [X1, X2], np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8sfBAM0EZW2",
        "outputId": "ed25243c-e07a-4965-80e5-92176e78f250"
      },
      "source": [
        "from arcface import ArcFace\n",
        "from arcface.lib.models import ArcFaceModel\n",
        "\n",
        "face_rec = ArcFace.ArcFace()\n",
        "test = gen(train, train_person_to_images_map, batch_size=16)\n",
        "img = next(test)\n",
        "\n",
        "af_model = ArcFaceModel(size=224, channels=3, num_classes=None, name='arcface_model',\n",
        "                 margin=0.5, logist_scale=64, embd_shape=512,\n",
        "                 head_type='ArcHead', backbone_type='ResNet50',\n",
        "                 w_decay=5e-4, use_pretrain=True, training=False)\n",
        "\n",
        "#emb2 = face_rec.calc_emb([img[0][0][0],img[0][0][1]])\n",
        "#print(emb1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twqQbfVIE_HX",
        "outputId": "435579aa-dc67-4e52-eed6-2b2828eb2ce7"
      },
      "source": [
        "type(af_model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.keras.engine.functional.Functional"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF5-VDGuy88K",
        "outputId": "50bc8157-a3db-4774-d8ea-f0ac2cb470ea"
      },
      "source": [
        "len(img[0][0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "224"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m6jv8JdVFnb",
        "outputId": "81be2c00-d64b-4418-81b5-b125e139102a"
      },
      "source": [
        "dist = np.linalg.norm(emb1 - emb2)\n",
        "sim = np.dot(emb1, emb2) / (np.sqrt(np.dot(emb1,emb1)) * np.sqrt(np.dot(emb2,emb2)))\n",
        "print(dist)\n",
        "print(sim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.1992311\n",
            "0.2809223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bbXIotMlty4",
        "outputId": "8619bebf-ff4b-4d45-8953-d9191d646d0d"
      },
      "source": [
        "val"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('F0917/MID3/P09684_face0.jpg', 'F0290/MID6/P03086_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID1/P02146_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0167/MID4/P01797_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0939/MID3/P09902_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID1/P12313_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0665/MID4/P06953_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0119/MID1/P01238_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0841/MID1/P08886_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID5/P10928_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0421/MID3/P04429_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0930/MID2/P09812_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0457/MID1/P04834_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0736/MID1/P07716_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0573/MID1/P06024_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0511/MID2/P05392_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0139/MID3/P01467_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0205/MID7/P02196_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0873/MID5/P09223_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0547/MID2/P05744_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0769/MID1/P08121_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0910/MID5/P09609_face6.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0147/MID4/P01591_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0344/MID2/P03660_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0724/MID2/P07604_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0724/MID1/P07607_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0709/MID4/P07416_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0736/MID1/P07708_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID6/P02151_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0220/MID4/P02336_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0873/MID3/P09220_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0791/MID1/P08337_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0407/MID2/P04286_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0351/MID2/P03717_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0440/MID2/P04644_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0290/MID4/P03088_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0311/MID1/P03314_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID3/P04444_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID1/P10934_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0071/MID3/P00723_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0133/MID3/P01399_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0939/MID4/P09900_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID6/P11274_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0488/MID3/P05132_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0443/MID1/P04681_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0165/MID3/P01775_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0513/MID1/P10958_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID3/P04447_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0836/MID1/P08832_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID3/P07887_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID1/P04456_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0170/MID2/P01822_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0820/MID2/P08680_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0621/MID4/P06516_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0183/MID5/P01966_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID5/P10932_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID1/P02144_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0719/MID1/P07535_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0091/MID1/P00937_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID5/P04435_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID1/P08437_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0731/MID7/P07665_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID4/P12299_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0126/MID1/P01313_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID1/P00079_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0481/MID1/P05068_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID4/P12292_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0417/MID7/P04382_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0450/MID3/P04759_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0665/MID4/P06957_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0836/MID2/P08840_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0139/MID3/P01471_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0728/MID3/P07639_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0172/MID3/P01844_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID5/P10935_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0481/MID1/P05071_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0053/MID3/P00524_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0930/MID5/P09812_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0450/MID3/P04764_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID1/P08413_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID4/P07895_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0750/MID5/P07854_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0832/MID3/P08799_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID4/P07896_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0450/MID4/P04761_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0769/MID1/P08125_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0905/MID2/P09558_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0312/MID4/P03323_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0183/MID1/P01963_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0970/MID2/P10217_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0409/MID3/P04308_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0440/MID1/P04639_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0815/MID5/P08614_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0705/MID2/P07381_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID1/P10936_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0755/MID3/P07976_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID1/P02142_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0162/MID1/P01731_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0112/MID3/P01162_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0769/MID7/P08124_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0930/MID2/P09810_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0750/MID1/P07861_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0087/MID3/P00893_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0123/MID5/P01282_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0183/MID5/P01960_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0547/MID4/P05739_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0243/MID1/P02571_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0342/MID3/P03634_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0872/MID4/P09213_face7.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID4/P07907_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0785/MID4/P08290_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID5/P04434_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0652/MID4/P11015_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0547/MID4/P05740_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0547/MID2/P05739_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0183/MID5/P01957_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0139/MID3/P01472_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0351/MID2/P03716_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0617/MID1/P06479_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0205/MID7/P02195_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0831/MID5/P08790_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0245/MID5/P02590_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0728/MID4/P07636_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0063/MID3/P00634_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0342/MID1/P03646_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0119/MID1/P01241_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0240/MID1/P02541_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0943/MID3/P09937_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0791/MID7/P08334_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0370/MID2/P03927_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0620/MID2/P06503_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID3/P04458_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0644/MID2/P06777_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID4/P10934_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0162/MID4/P01733_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0621/MID4/P06518_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0750/MID3/P07861_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0667/MID1/P06968_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0724/MID1/P07612_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0513/MID1/P10953_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID3/P00078_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0147/MID4/P01588_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0281/MID3/P02997_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0427/MID2/P04496_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID1/P10430_face6.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0183/MID5/P01962_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0573/MID1/P06020_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0660/MID5/P09494_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0133/MID3/P09132_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0785/MID2/P08290_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0573/MID5/P06029_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0831/MID3/P08786_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID4/P12305_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0074/MID2/P11163_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0689/MID1/P07188_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID1/P12302_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0705/MID1/P07377_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0879/MID3/P09276_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0769/MID3/P08121_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID10/P03110_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0443/MID1/P04677_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0470/MID4/P04955_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0317/MID5/P03358_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0826/MID3/P08731_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0831/MID1/P08782_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0713/MID1/P07472_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0669/MID4/P06992_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0488/MID3/P05136_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0832/MID3/P08794_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0652/MID4/P11011_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0513/MID9/P10958_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0627/MID3/P06582_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0853/MID3/P09019_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0713/MID2/P07468_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0873/MID3/P09221_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0123/MID6/P01275_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0689/MID4/P07195_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0769/MID1/P08127_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0390/MID5/P04134_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID1/P04612_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0147/MID4/P01591_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID5/P10388_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID4/P10949_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0652/MID5/P11011_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID1/P08416_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID8/P11276_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0547/MID4/P05736_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0421/MID3/P04428_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0809/MID1/P08564_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID1/P02141_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0873/MID6/P09219_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0123/MID3/P01277_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0240/MID3/P02542_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID3/P04637_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0633/MID5/P06650_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0440/MID2/P04640_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0511/MID2/P05391_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0053/MID5/P00524_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0351/MID2/P03719_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0831/MID4/P08783_face6.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0581/MID2/P06107_face11.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0633/MID3/P06650_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0281/MID3/P02989_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0826/MID4/P08737_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0939/MID3/P09898_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0999/MID2/P10551_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0450/MID4/P04757_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0398/MID6/P04201_face8.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0040/MID3/P00415_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0893/MID4/P09428_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID3/P04457_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0568/MID1/P05975_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0220/MID4/P02334_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0386/MID4/P04093_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0907/MID3/P09583_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0427/MID3/P04491_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID4/P10437_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID2/P07905_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0697/MID3/P07271_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0238/MID7/P02525_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID3/P10944_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID3/P07878_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0147/MID4/P01580_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0312/MID3/P03323_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0183/MID1/P01962_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID1/P10428_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID4/P12310_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0290/MID2/P03090_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0170/MID1/P01828_face14.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID3/P12307_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID5/P04460_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0071/MID3/P00724_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0573/MID1/P06029_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0750/MID1/P07853_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0457/MID1/P04837_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID1/P08430_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0785/MID5/P08284_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0091/MID3/P00931_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0832/MID5/P08793_face6.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0170/MID3/P01827_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID1/P10431_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID5/P09343_face22.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0427/MID4/P04491_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0317/MID5/P03363_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID5/P10390_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0627/MID3/P06584_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0421/MID7/P04423_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0390/MID3/P04131_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0159/MID2/P01701_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0468/MID3/P04940_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID1/P02149_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0728/MID5/P07638_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0826/MID3/P08735_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0996/MID5/P10523_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0087/MID4/P00893_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0053/MID4/P00523_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0446/MID3/P04721_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0468/MID2/P04938_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0705/MID2/P07391_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID2/P04621_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID4/P00076_face6.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0233/MID6/P02472_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0632/MID2/P06633_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0427/MID3/P04493_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0318/MID2/P03373_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0905/MID2/P09560_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0243/MID1/P02568_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID6/P10394_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0617/MID4/P06475_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0873/MID1/P09222_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0736/MID1/P07713_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0427/MID4/P04492_face6.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0674/MID4/P07040_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0147/MID4/P01590_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0832/MID4/P08794_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0290/MID2/P03087_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0724/MID2/P07605_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0750/MID4/P07853_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0384/MID2/P04083_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0563/MID2/P05918_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0873/MID4/P09215_face10.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0713/MID2/P07472_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0474/MID1/P04991_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0879/MID5/P09278_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0463/MID1/P04888_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0769/MID3/P08118_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0925/MID6/P09760_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0342/MID1/P03643_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0119/MID2/P01242_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID6/P10435_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0162/MID5/P01734_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0123/MID4/P01276_face6.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0644/MID5/P06783_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0421/MID9/P04430_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0278/MID4/P02960_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0910/MID2/P09610_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID6/P04636_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0809/MID1/P08560_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0490/MID1/P05167_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID2/P07900_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID2/P08411_face7.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID1/P10385_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0053/MID3/P00522_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0930/MID2/P09807_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0930/MID2/P09805_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0328/MID1/P03479_face8.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0996/MID1/P10522_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0573/MID1/P06027_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0660/MID3/P06911_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID4/P10429_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0573/MID1/P06025_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0183/MID5/P01959_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0568/MID5/P05971_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0243/MID1/P02577_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0652/MID4/P03819_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0516/MID2/P05439_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID5/P10933_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0785/MID6/P08288_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0769/MID1/P08117_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID3/P04437_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0091/MID1/P00934_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0236/MID4/P02503_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0468/MID3/P04935_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0872/MID8/P09214_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0736/MID3/P07717_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID3/P02141_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID1/P10388_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0133/MID3/P01394_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0785/MID7/P08286_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0398/MID3/P04196_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID1/P04627_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0123/MID5/P01276_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0386/MID3/P04090_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID1/P04615_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0170/MID3/P01831_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0679/MID2/P07085_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0921/MID1/P09723_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0448/MID1/P04742_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0169/MID4/P01819_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0183/MID1/P01961_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0758/MID2/P08001_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID3/P00080_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0931/MID3/P09819_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0126/MID2/P01298_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0573/MID1/P06023_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0398/MID7/P04201_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0398/MID3/P04198_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0266/MID2/P02825_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0930/MID4/P09809_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0931/MID3/P09824_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0724/MID2/P07608_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0713/MID1/P07468_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0809/MID3/P08559_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID1/P08412_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0652/MID5/P11010_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0133/MID1/P09127_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID3/P10950_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID2/P08430_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0409/MID3/P04310_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0562/MID3/P05903_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0627/MID3/P06578_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0800/MID3/P08463_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0487/MID1/P05127_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0287/MID3/P03067_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0769/MID1/P08120_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0581/MID5/P06105_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0162/MID1/P01732_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0705/MID1/P07370_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0621/MID2/P06516_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0450/MID2/P04763_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0390/MID1/P04131_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0563/MID4/P05915_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0450/MID2/P04762_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID3/P07901_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0713/MID1/P07474_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0074/MID1/P11160_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0351/MID2/P03718_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0831/MID5/P08787_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0133/MID1/P01395_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0123/MID3/P01282_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0312/MID1/P03326_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0119/MID1/P01234_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0919/MID3/P09696_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0836/MID1/P08838_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0063/MID3/P00633_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0236/MID2/P02495_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0147/MID1/P01591_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0927/MID1/P09775_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID7/P07904_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0182/MID2/P01947_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0832/MID5/P08796_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0573/MID5/P06028_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0674/MID3/P07035_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0328/MID1/P03482_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0927/MID3/P09781_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0925/MID3/P09759_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0457/MID6/P04830_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0660/MID6/P09494_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0342/MID2/P03642_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID5/P09336_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0872/MID8/P09205_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0697/MID3/P07265_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0183/MID5/P01965_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID2/P07896_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0568/MID5/P05980_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0568/MID4/P05975_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0916/MID3/P09672_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0927/MID1/P09780_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0443/MID5/P04680_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID3/P04434_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0531/MID3/P05583_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID1/P11274_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID1/P04618_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0421/MID3/P04430_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0443/MID1/P04673_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0681/MID1/P07106_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0318/MID2/P03372_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0074/MID1/P11162_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0407/MID2/P04285_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0236/MID4/P02493_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0681/MID2/P07110_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0872/MID7/P09214_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0162/MID4/P01737_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0831/MID4/P08789_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0139/MID1/P01470_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0621/MID3/P06522_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0674/MID5/P07041_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0040/MID2/P00415_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0139/MID3/P01468_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0133/MID1/P01397_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0665/MID3/P06956_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0927/MID1/P09776_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0705/MID2/P07372_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0390/MID1/P04136_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0123/MID4/P01277_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID5/P03105_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0309/MID2/P12245_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID1/P04441_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0427/MID4/P04496_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0278/MID3/P02965_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0053/MID4/P00526_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0390/MID1/P04137_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID3/P04627_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID9/P10437_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0800/MID3/P08465_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0511/MID3/P05396_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0500/MID2/P05290_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0427/MID3/P04495_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0386/MID4/P04095_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0148/MID2/P01602_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0603/MID3/P06349_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID3/P12297_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0925/MID6/P09758_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID13/P10430_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0200/MID5/P02158_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0148/MID2/P01598_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0421/MID10/P04423_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0581/MID5/P06101_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0446/MID2/P04717_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0568/MID4/P05971_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0170/MID2/P01826_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0666/MID2/P06962_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0176/MID3/P01898_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0240/MID1/P02539_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0872/MID7/P09206_face7.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0873/MID1/P09215_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0087/MID4/P00891_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID4/P07897_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID1/P08411_face8.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0736/MID1/P07711_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID8/P10433_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0040/MID3/P00413_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0674/MID3/P07043_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0649/MID4/P06838_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0071/MID1/P00725_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0446/MID2/P04712_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0608/MID7/P10775_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0893/MID3/P09424_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0427/MID2/P04493_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0697/MID3/P07270_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID1/P02133_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0513/MID6/P10952_face10.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0620/MID2/P06511_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0575/MID2/P06044_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0996/MID5/P10524_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0233/MID4/P02471_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0750/MID1/P07858_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0674/MID5/P07040_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0735/MID3/P07698_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0165/MID3/P01772_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0290/MID2/P03089_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0736/MID2/P07714_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0516/MID1/P05441_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID1/P04442_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0627/MID3/P06583_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0930/MID2/P09806_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0766/MID1/P08098_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0344/MID2/P10605_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0448/MID1/P04744_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0689/MID1/P07194_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0620/MID3/P06510_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0633/MID4/P06649_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0370/MID2/P03919_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0490/MID1/P05161_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0053/MID3/P00521_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0568/MID5/P05978_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0488/MID4/P05133_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID1/P02139_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID2/P07892_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID6/P04631_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0705/MID1/P07387_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0278/MID4/P02966_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0927/MID2/P09780_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0925/MID1/P09758_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0165/MID4/P01775_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0243/MID2/P02570_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0450/MID3/P04758_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0114/MID1/P01181_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0342/MID1/P03645_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0172/MID3/P01847_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0919/MID2/P09700_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0112/MID2/P01161_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0697/MID3/P07266_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID5/P03112_face6.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0200/MID4/P02159_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0481/MID3/P05070_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID3/P10928_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0112/MID3/P01161_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID4/P10933_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0074/MID1/P00760_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0633/MID4/P06650_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0311/MID2/P03312_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0522/MID3/P05487_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0290/MID2/P03084_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0162/MID5/P01738_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0147/MID1/P01584_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID5/P11274_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID3/P04454_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0278/MID4/P02961_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID3/P12308_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0065/MID1/P00657_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID4/P12302_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0427/MID4/P04493_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0925/MID1/P09759_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0568/MID1/P05974_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0126/MID1/P01299_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0833/MID1/P08807_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID1/P10430_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0735/MID3/P07700_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0091/MID1/P00938_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0679/MID3/P07085_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0674/MID4/P07038_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0581/MID2/P06102_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0693/MID3/P07221_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0407/MID2/P04283_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID1/P10428_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID4/P12297_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0481/MID5/P05066_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0250/MID3/P02660_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0758/MID2/P07999_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0457/MID1/P04835_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0513/MID4/P10964_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID1/P02145_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0511/MID3/P05392_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0487/MID2/P05128_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID3/P10945_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0709/MID3/P07414_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0603/MID3/P06352_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0893/MID4/P09423_face13.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0133/MID1/P09128_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID4/P12306_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0931/MID3/P09823_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0457/MID5/P04822_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0674/MID4/P07046_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0674/MID3/P07045_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0853/MID3/P09012_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0290/MID4/P03089_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0538/MID2/P05649_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0290/MID6/P03087_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID1/P08438_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0446/MID2/P04714_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0119/MID1/P01239_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0053/MID2/P00521_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0443/MID4/P04680_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0919/MID4/P09702_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0490/MID7/P05166_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID2/P04618_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0853/MID3/P09010_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0750/MID1/P07854_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0333/MID7/P03529_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0283/MID1/P03024_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0666/MID2/P06961_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0999/MID1/P10553_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0126/MID2/P01297_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0390/MID7/P04136_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0440/MID2/P04643_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0719/MID1/P07540_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID5/P04439_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID2/P07894_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0568/MID1/P05978_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID3/P07907_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0750/MID8/P07860_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0233/MID3/P02468_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0873/MID7/P09215_face11.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0172/MID5/P01844_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID1/P08436_face11.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID4/P12294_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID2/P08437_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0912/MID4/P09632_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0119/MID2/P01236_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0318/MID2/P03382_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0390/MID5/P04132_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID3/P10949_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID8/P10429_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0311/MID2/P03310_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0820/MID2/P08676_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0133/MID3/P01389_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0240/MID1/P02538_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0758/MID2/P08002_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0390/MID1/P04127_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0114/MID3/P01186_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0278/MID4/P02964_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0841/MID5/P08884_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0133/MID1/P01396_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0063/MID3/P00631_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0162/MID1/P01738_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0245/MID5/P02589_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID1/P04613_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0126/MID1/P01303_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0563/MID2/P05911_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0832/MID3/P08797_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID1/P04630_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0785/MID3/P08283_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID3/P02136_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0114/MID5/P01182_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID4/P12313_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID1/P00076_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0943/MID3/P09942_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0312/MID5/P03322_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0448/MID2/P04739_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0290/MID3/P03087_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0370/MID1/P03927_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0176/MID5/P01897_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID4/P10945_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0914/MID4/P09647_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0071/MID1/P00728_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID1/P11232_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0620/MID2/P06505_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0283/MID4/P03018_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0832/MID4/P08797_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0114/MID5/P01184_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0669/MID4/P06993_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0731/MID2/P07662_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0930/MID4/P09811_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0785/MID2/P08282_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0162/MID4/P01740_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID1/P09343_face16.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0457/MID1/P04821_face6.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0644/MID2/P06783_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0324/MID3/P03441_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID3/P04439_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0575/MID2/P06052_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0513/MID5/P10953_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0667/MID1/P06975_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0996/MID2/P10529_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0809/MID1/P08562_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID1/P09336_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0853/MID3/P09014_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0724/MID2/P07607_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0914/MID1/P09650_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0836/MID1/P08837_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0879/MID6/P09284_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0311/MID2/P03311_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0603/MID3/P06359_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0617/MID1/P06475_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0750/MID1/P07860_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID1/P06405_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0399/MID2/P04207_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0925/MID5/P09758_face7.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0427/MID2/P04491_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0871/MID3/P09195_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID2/P08438_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0170/MID3/P01828_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0176/MID3/P01891_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID4/P07888_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0147/MID1/P01579_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0736/MID3/P07711_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0836/MID1/P08834_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0490/MID2/P05149_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0226/MID5/P02409_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0547/MID2/P05738_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0705/MID1/P07372_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID1/P03112_face8.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID5/P10387_face8.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0172/MID3/P01843_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0398/MID8/P04195_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0133/MID1/P01399_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0731/MID5/P07663_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0278/MID3/P02960_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0516/MID1/P05439_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0448/MID3/P04733_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0538/MID3/P05649_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0679/MID2/P07083_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0162/MID5/P01737_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0324/MID5/P03442_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID7/P10435_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0633/MID3/P06648_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0126/MID2/P01307_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID7/P10437_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0581/MID9/P06105_face6.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0342/MID1/P03638_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0312/MID4/P03319_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0943/MID4/P09936_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0735/MID3/P07697_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0182/MID2/P01946_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0330/MID4/P03501_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0970/MID2/P10220_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F1004/MID3/P13032_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0330/MID4/P03494_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0573/MID3/P06021_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0831/MID3/P08789_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID3/P07905_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0162/MID1/P01734_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0487/MID1/P05129_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID3/P04612_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0170/MID2/P01824_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID1/P04457_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0147/MID1/P01577_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0427/MID4/P04498_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0912/MID3/P09625_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0370/MID1/P03919_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0879/MID3/P09279_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0652/MID4/P03822_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0287/MID4/P03066_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0290/MID3/P03085_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0091/MID3/P00932_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0531/MID3/P05574_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0766/MID4/P08091_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0681/MID2/P07109_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0873/MID4/P09218_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0919/MID4/P09701_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0446/MID2/P04721_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0417/MID7/P04386_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0893/MID4/P09422_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0290/MID3/P03093_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID6/P04630_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0728/MID5/P07636_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID3/P12311_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0481/MID1/P05073_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0681/MID3/P07106_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0755/MID1/P07976_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0384/MID2/P04082_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0044/MID2/P00439_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0750/MID3/P07853_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0417/MID4/P04383_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0278/MID3/P02959_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0450/MID2/P04765_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0488/MID3/P05139_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0633/MID5/P06643_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0617/MID3/P06478_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0139/MID1/P01466_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0457/MID6/P04836_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0815/MID5/P08616_face6.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0312/MID3/P03320_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0620/MID2/P06504_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0283/MID5/P03019_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0538/MID2/P05652_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0831/MID3/P08783_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0912/MID4/P09627_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0511/MID3/P05393_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID2/P07909_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0713/MID4/P07468_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0841/MID1/P08884_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0815/MID4/P08616_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0530/MID4/P05573_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID5/P09344_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0633/MID4/P06651_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0617/MID6/P06474_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0674/MID3/P07040_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0513/MID3/P10952_face8.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0513/MID6/P10953_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID6/P02150_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0290/MID4/P03093_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0674/MID3/P07034_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0621/MID3/P06515_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0474/MID1/P04990_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0245/MID4/P02589_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0568/MID1/P05981_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID10/P10388_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0443/MID6/P04679_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID1/P03106_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0071/MID1/P00720_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0318/MID2/P03375_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0162/MID5/P01733_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0652/MID1/P03818_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0982/MID2/P10352_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID3/P10930_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0820/MID2/P08672_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0914/MID3/P09650_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0087/MID4/P00892_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0575/MID2/P06048_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0841/MID3/P08882_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0443/MID1/P04674_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID8/P10435_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID6/P04637_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0226/MID5/P02411_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0505/MID4/P05330_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0858/MID1/P09066_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0114/MID5/P01190_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0910/MID5/P09611_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0071/MID4/P00723_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0360/MID1/P12295_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID12/P04450_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0119/MID2/P01234_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0398/MID5/P04196_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0167/MID3/P01804_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID3/P04616_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0123/MID5/P01278_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0407/MID2/P04287_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID6/P00073_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0390/MID1/P04132_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0040/MID2/P00411_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0457/MID1/P04825_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0679/MID3/P07086_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0873/MID6/P09216_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0731/MID5/P07662_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0450/MID3/P04761_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0921/MID6/P09724_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0769/MID1/P08116_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID5/P10394_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0233/MID2/P02468_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID5/P03104_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0468/MID1/P04939_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0390/MID8/P04136_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0939/MID3/P09901_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0236/MID4/P02505_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0123/MID6/P01278_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0200/MID1/P02157_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0091/MID3/P00933_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0873/MID1/P09216_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0474/MID2/P04992_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0617/MID1/P06474_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID1/P03107_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0530/MID4/P05570_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0632/MID2/P06637_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0147/MID4/P01583_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0990/MID1/P06410_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0390/MID5/P04127_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0713/MID2/P07474_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0074/MID1/P11159_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID4/P10928_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0409/MID3/P04305_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0199/MID6/P02149_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0736/MID1/P07715_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0333/MID3/P03528_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0705/MID2/P07371_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0797/MID2/P08417_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0713/MID2/P07469_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID1/P00081_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0422/MID10/P04449_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0652/MID4/P03817_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0457/MID6/P04822_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0705/MID1/P07382_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0358/MID1/P10938_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0342/MID1/P03644_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0921/MID3/P09715_face6.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0752/MID3/P07881_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0970/MID3/P10217_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0126/MID1/P01300_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0126/MID2/P01306_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0996/MID3/P10516_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0139/MID2/P01473_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID5/P00073_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0022/MID1/P00220_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0266/MID2/P02834_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0328/MID1/P03478_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID11/P10383_face7.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0071/MID3/P00722_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0278/MID4/P02958_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0007/MID1/P00074_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0632/MID4/P06634_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0930/MID5/P09809_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0766/MID4/P08098_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0769/MID3/P08123_face3.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID5/P10389_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0510/MID4/P05384_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0398/MID7/P04195_face4.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID1/P03110_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0283/MID5/P03026_face0.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0438/MID1/P04628_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0689/MID3/P07194_face2.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0568/MID1/P05982_face1.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0986/MID10/P10387_face5.jpg', 0),\n",
              " ('F0917/MID3/P09684_face0.jpg', 'F0133/MID1/P09131_face2.jpg', 0),\n",
              " ('F0986/MID1/P10390_face5.jpg', 'F0986/MID10/P10383_face1.jpg', 1),\n",
              " ('F0986/MID4/P10387_face7.jpg', 'F0986/MID6/P10386_face1.jpg', 1),\n",
              " ('F0925/MID1/P09758_face3.jpg', 'F0925/MID8/P09760_face4.jpg', 1),\n",
              " ('F0986/MID1/P10392_face2.jpg', 'F0986/MID10/P10393_face0.jpg', 1),\n",
              " ('F0914/MID2/P09645_face0.jpg', 'F0914/MID1/P09650_face1.jpg', 1),\n",
              " ('F0986/MID7/P03113_face1.jpg', 'F0986/MID10/P10392_face0.jpg', 1),\n",
              " ('F0990/MID4/P10431_face4.jpg', 'F0990/MID7/P10429_face3.jpg', 1),\n",
              " ('F0990/MID6/P10432_face8.jpg', 'F0990/MID8/P10435_face0.jpg', 1),\n",
              " ('F0986/MID7/P03107_face1.jpg', 'F0986/MID5/P10392_face4.jpg', 1),\n",
              " ('F0986/MID1/P10385_face3.jpg', 'F0986/MID5/P03110_face3.jpg', 1),\n",
              " ('F0990/MID6/P10432_face7.jpg', 'F0990/MID9/P10437_face5.jpg', 1),\n",
              " ('F0990/MID10/P10431_face5.jpg', 'F0990/MID8/P10429_face4.jpg', 1),\n",
              " ('F0990/MID10/P10434_face0.jpg', 'F0990/MID7/P10433_face5.jpg', 1),\n",
              " ('F0990/MID6/P10436_face5.jpg', 'F0990/MID8/P10433_face2.jpg', 1),\n",
              " ('F0996/MID1/P10529_face2.jpg', 'F0996/MID3/P10516_face1.jpg', 1),\n",
              " ('F0990/MID10/P10434_face0.jpg', 'F0990/MID1/P10432_face9.jpg', 1),\n",
              " ('F0999/MID2/P10551_face3.jpg', 'F0999/MID3/P10553_face0.jpg', 1),\n",
              " ('F0917/MID1/P09677_face3.jpg', 'F0917/MID2/P09678_face2.jpg', 1),\n",
              " ('F0996/MID4/P10526_face1.jpg', 'F0996/MID3/P10517_face0.jpg', 1),\n",
              " ('F0990/MID3/P10428_face4.jpg', 'F0990/MID9/P10433_face2.jpg', 1),\n",
              " ('F0986/MID7/P03113_face1.jpg', 'F0986/MID10/P10393_face0.jpg', 1),\n",
              " ('F0990/MID6/P10435_face2.jpg', 'F0990/MID9/P10437_face5.jpg', 1),\n",
              " ('F0990/MID3/P10436_face5.jpg', 'F0990/MID1/P10428_face3.jpg', 1),\n",
              " ('F0990/MID7/P10437_face1.jpg', 'F0990/MID8/P10435_face4.jpg', 1),\n",
              " ('F0990/MID5/P10432_face5.jpg', 'F0990/MID8/P10433_face2.jpg', 1),\n",
              " ('F0990/MID3/P06403_face1.jpg', 'F0990/MID9/P10437_face3.jpg', 1),\n",
              " ('F0990/MID6/P10432_face7.jpg', 'F0990/MID7/P10433_face5.jpg', 1),\n",
              " ('F0986/MID7/P10387_face0.jpg', 'F0986/MID1/P10388_face4.jpg', 1),\n",
              " ('F0939/MID2/P09898_face0.jpg', 'F0939/MID4/P09898_face4.jpg', 1),\n",
              " ('F0990/MID7/P10437_face4.jpg', 'F0990/MID9/P10435_face5.jpg', 1),\n",
              " ('F0990/MID10/P06404_face2.jpg', 'F0990/MID1/P06410_face1.jpg', 1),\n",
              " ('F0943/MID2/P09942_face2.jpg', 'F0943/MID4/P09936_face0.jpg', 1),\n",
              " ('F0986/MID5/P03112_face6.jpg', 'F0986/MID10/P10388_face0.jpg', 1),\n",
              " ('F0986/MID7/P03108_face4.jpg', 'F0986/MID10/P03110_face0.jpg', 1),\n",
              " ('F0990/MID4/P10429_face0.jpg', 'F0990/MID9/P10429_face1.jpg', 1),\n",
              " ('F0986/MID7/P03113_face1.jpg', 'F0986/MID5/P03111_face3.jpg', 1),\n",
              " ('F0921/MID2/P09715_face3.jpg', 'F0921/MID3/P09721_face1.jpg', 1),\n",
              " ('F0986/MID8/P10392_face3.jpg', 'F0986/MID5/P10388_face3.jpg', 1),\n",
              " ('F0986/MID4/P10394_face2.jpg', 'F0986/MID6/P10395_face4.jpg', 1),\n",
              " ('F0919/MID2/P09695_face1.jpg', 'F0919/MID4/P09701_face2.jpg', 1),\n",
              " ('F0986/MID1/P03104_face0.jpg', 'F0986/MID5/P10394_face3.jpg', 1),\n",
              " ('F0990/MID3/P10428_face5.jpg', 'F0990/MID1/P10431_face6.jpg', 1),\n",
              " ('F0910/MID1/P09613_face1.jpg', 'F0910/MID5/P09608_face0.jpg', 1),\n",
              " ('F0986/MID1/P10387_face6.jpg', 'F0986/MID5/P10389_face0.jpg', 1),\n",
              " ('F0921/MID5/P09716_face1.jpg', 'F0921/MID3/P09716_face3.jpg', 1),\n",
              " ('F0990/MID10/P10428_face1.jpg', 'F0990/MID6/P10437_face5.jpg', 1),\n",
              " ('F0986/MID5/P10388_face3.jpg', 'F0986/MID10/P10387_face5.jpg', 1),\n",
              " ('F0990/MID6/P10429_face1.jpg', 'F0990/MID9/P10437_face3.jpg', 1),\n",
              " ('F0912/MID1/P09633_face2.jpg', 'F0912/MID3/P09626_face2.jpg', 1),\n",
              " ('F0986/MID1/P03108_face1.jpg', 'F0986/MID5/P10387_face8.jpg', 1),\n",
              " ('F0986/MID7/P10390_face4.jpg', 'F0986/MID1/P10393_face2.jpg', 1),\n",
              " ('F0986/MID1/P10386_face0.jpg', 'F0986/MID10/P03110_face0.jpg', 1),\n",
              " ('F0970/MID4/P10218_face3.jpg', 'F0970/MID3/P10217_face2.jpg', 1),\n",
              " ('F0919/MID5/P09700_face2.jpg', 'F0919/MID4/P09701_face2.jpg', 1),\n",
              " ('F0990/MID10/P10431_face3.jpg', 'F0990/MID9/P10437_face5.jpg', 1),\n",
              " ('F0986/MID1/P10388_face4.jpg', 'F0986/MID5/P10393_face1.jpg', 1),\n",
              " ('F0990/MID4/P10432_face4.jpg', 'F0990/MID6/P10437_face5.jpg', 1),\n",
              " ('F0970/MID1/P10220_face2.jpg', 'F0970/MID3/P10213_face2.jpg', 1),\n",
              " ('F0986/MID8/P10393_face4.jpg', 'F0986/MID6/P10394_face1.jpg', 1),\n",
              " ('F0990/MID8/P10433_face2.jpg', 'F0990/MID9/P10435_face5.jpg', 1),\n",
              " ('F0990/MID8/P10433_face1.jpg', 'F0990/MID9/P10433_face2.jpg', 1),\n",
              " ('F0986/MID8/P03104_face4.jpg', 'F0986/MID5/P10389_face0.jpg', 1),\n",
              " ('F0990/MID5/P10433_face1.jpg', 'F0990/MID9/P10437_face3.jpg', 1),\n",
              " ('F0986/MID5/P03111_face3.jpg', 'F0986/MID6/P10395_face4.jpg', 1),\n",
              " ('F0986/MID8/P10390_face2.jpg', 'F0986/MID1/P03107_face0.jpg', 1),\n",
              " ('F0996/MID4/P10525_face0.jpg', 'F0996/MID2/P10529_face0.jpg', 1),\n",
              " ('F0907/MID2/P09580_face1.jpg', 'F0907/MID3/P09584_face6.jpg', 1),\n",
              " ('F0990/MID4/P10436_face3.jpg', 'F0990/MID9/P10433_face2.jpg', 1),\n",
              " ('F0939/MID2/P09895_face3.jpg', 'F0939/MID4/P09900_face1.jpg', 1),\n",
              " ('F0990/MID1/P10431_face6.jpg', 'F0990/MID4/P10429_face2.jpg', 1),\n",
              " ('F0986/MID1/P03105_face1.jpg', 'F0986/MID10/P10392_face0.jpg', 1),\n",
              " ('F0999/MID4/P10558_face0.jpg', 'F0999/MID5/P10560_face0.jpg', 1),\n",
              " ('F0986/MID1/P03106_face0.jpg', 'F0986/MID10/P03110_face0.jpg', 1),\n",
              " ('F0990/MID5/P10429_face3.jpg', 'F0990/MID6/P10437_face5.jpg', 1),\n",
              " ('F0990/MID10/P10431_face3.jpg', 'F0990/MID6/P10437_face5.jpg', 1),\n",
              " ('F0986/MID8/P03111_face2.jpg', 'F0986/MID5/P03104_face1.jpg', 1),\n",
              " ('F0939/MID2/P09901_face1.jpg', 'F0939/MID3/P09903_face0.jpg', 1),\n",
              " ('F0986/MID7/P03111_face1.jpg', 'F0986/MID6/P10395_face4.jpg', 1),\n",
              " ('F0939/MID1/P09903_face5.jpg', 'F0939/MID3/P09902_face5.jpg', 1),\n",
              " ('F0986/MID8/P03111_face2.jpg', 'F0986/MID1/P10385_face3.jpg', 1),\n",
              " ('F0990/MID3/P10436_face5.jpg', 'F0990/MID6/P10429_face1.jpg', 1),\n",
              " ('F0986/MID1/P10385_face3.jpg', 'F0986/MID10/P10383_face1.jpg', 1),\n",
              " ('F0986/MID5/P10387_face8.jpg', 'F0986/MID10/P10393_face0.jpg', 1),\n",
              " ('F0939/MID3/P09902_face5.jpg', 'F0939/MID4/P09900_face1.jpg', 1),\n",
              " ('F0996/MID1/P10529_face2.jpg', 'F0996/MID2/P10516_face2.jpg', 1),\n",
              " ('F0986/MID7/P03113_face1.jpg', 'F0986/MID5/P10394_face3.jpg', 1),\n",
              " ('F0986/MID1/P03108_face1.jpg', 'F0986/MID10/P10383_face1.jpg', 1),\n",
              " ('F0990/MID3/P10436_face0.jpg', 'F0990/MID6/P10433_face3.jpg', 1),\n",
              " ('F0986/MID5/P10389_face0.jpg', 'F0986/MID10/P03107_face2.jpg', 1),\n",
              " ('F0986/MID1/P10392_face2.jpg', 'F0986/MID5/P03105_face0.jpg', 1),\n",
              " ('F0986/MID1/P10390_face5.jpg', 'F0986/MID10/P10392_face0.jpg', 1),\n",
              " ('F0990/MID6/P10435_face2.jpg', 'F0990/MID9/P10433_face6.jpg', 1),\n",
              " ('F0925/MID1/P09760_face2.jpg', 'F0925/MID8/P09760_face4.jpg', 1),\n",
              " ('F0990/MID3/P06403_face0.jpg', 'F0990/MID1/P06410_face1.jpg', 1),\n",
              " ('F0990/MID8/P10437_face6.jpg', 'F0990/MID9/P10429_face4.jpg', 1),\n",
              " ('F0986/MID8/P10393_face4.jpg', 'F0986/MID10/P10388_face0.jpg', 1),\n",
              " ('F0907/MID2/P09575_face1.jpg', 'F0907/MID3/P09576_face1.jpg', 1),\n",
              " ('F0990/MID3/P10428_face5.jpg', 'F0990/MID7/P10435_face5.jpg', 1),\n",
              " ('F0927/MID1/P09780_face1.jpg', 'F0927/MID2/P09779_face2.jpg', 1),\n",
              " ('F0986/MID1/P10386_face0.jpg', 'F0986/MID10/P03105_face2.jpg', 1),\n",
              " ('F0986/MID7/P03110_face4.jpg', 'F0986/MID10/P10383_face1.jpg', 1),\n",
              " ('F0990/MID3/P06404_face1.jpg', 'F0990/MID6/P10432_face8.jpg', 1),\n",
              " ('F0986/MID1/P03110_face1.jpg', 'F0986/MID5/P03112_face6.jpg', 1),\n",
              " ('F0927/MID1/P09776_face0.jpg', 'F0927/MID2/P09780_face2.jpg', 1),\n",
              " ('F0986/MID5/P10392_face4.jpg', 'F0986/MID10/P10393_face0.jpg', 1),\n",
              " ('F0986/MID1/P10383_face2.jpg', 'F0986/MID10/P10388_face0.jpg', 1),\n",
              " ('F0990/MID3/P10428_face4.jpg', 'F0990/MID7/P10437_face4.jpg', 1),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvPvyRzBw-nt"
      },
      "source": [
        "Here is an ensemble model built with two resnet-50 architectures, pre-trained, with which we can apply transfer leraning on. This model achieves the baseline and the goal is to expand on this work. There have been papers exploring different architectures as well as introducing BatchNormalization among many other techniques to improve how well the model recognizes kinship between two faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BBZJpieAi7Y"
      },
      "source": [
        "\n",
        "def baseline_model():\n",
        "    input_1 = Input(shape=(224, 224, 3))\n",
        "    input_2 = Input(shape=(224, 224, 3))\n",
        "\n",
        "    #base_model = VGGFace(model='resnet50', include_top=False)\n",
        "   \n",
        "    base_model = ArcFaceModel(size=224, channels=3, num_classes=None, name='arcface_model',\n",
        "                 margin=0.5, logist_scale=64, embd_shape=512,\n",
        "                 head_type='ArcHead', backbone_type='ResNet50',\n",
        "                 w_decay=5e-4, use_pretrain=True, training=False)\n",
        "    print(type(base_model))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    for x in base_model.layers[:-2]:\n",
        "        x.trainable = True\n",
        "\n",
        "    x1 = base_model(input_1)\n",
        "    x2 = base_model(input_2)\n",
        "\n",
        "    #x1 = Concatenate(axis=-1)([GlobalMaxPool2D()(x1), GlobalAvgPool2D()(x1)])\n",
        "    #x2 = Concatenate(axis=-1)([GlobalMaxPool2D()(x2), GlobalAvgPool2D()(x2)])\n",
        "\n",
        "    x3 = Subtract()([x1, x2])\n",
        "    x3 = Multiply()([x3, x3])\n",
        "\n",
        "    x = Multiply()([x1, x2])\n",
        "\n",
        "    x = Concatenate(axis=-1)([x, x3])\n",
        "\n",
        "    x = Dense(100, activation=\"relu\")(x)\n",
        "    x = Dropout(0.05)(x)\n",
        "    out = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model([input_1, input_2], out)\n",
        "\n",
        "    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMF0hWE4UcGA"
      },
      "source": [
        "# ArFace embedding with cosine distance - No transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC3TNCLWx5RC"
      },
      "source": [
        "Save the best model to your drive after each training epoch so that you can come back to it. ReduceLROnPlateau reduces the learning rate when a metric has stopped improving, in this case the validation accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "H_fM5Scprdmz",
        "outputId": "7a8b3160-d903-4384-846d-73fb95c00b48"
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>p1</th>\n",
              "      <th>p2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>face1116.jpg</td>\n",
              "      <td>face3426.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>face762.jpg</td>\n",
              "      <td>face3128.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>face1499.jpg</td>\n",
              "      <td>face3480.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>face1027.jpg</td>\n",
              "      <td>face1733.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>face158.jpg</td>\n",
              "      <td>face2620.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>2995</td>\n",
              "      <td>face2104.jpg</td>\n",
              "      <td>face4163.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>2996</td>\n",
              "      <td>face207.jpg</td>\n",
              "      <td>face2441.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>2997</td>\n",
              "      <td>face2024.jpg</td>\n",
              "      <td>face3753.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>2998</td>\n",
              "      <td>face1064.jpg</td>\n",
              "      <td>face3385.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>2999</td>\n",
              "      <td>face2423.jpg</td>\n",
              "      <td>face1524.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index            p1            p2\n",
              "0         0  face1116.jpg  face3426.jpg\n",
              "1         1   face762.jpg  face3128.jpg\n",
              "2         2  face1499.jpg  face3480.jpg\n",
              "3         3  face1027.jpg  face1733.jpg\n",
              "4         4   face158.jpg  face2620.jpg\n",
              "...     ...           ...           ...\n",
              "2995   2995  face2104.jpg  face4163.jpg\n",
              "2996   2996   face207.jpg  face2441.jpg\n",
              "2997   2997  face2024.jpg  face3753.jpg\n",
              "2998   2998  face1064.jpg  face3385.jpg\n",
              "2999   2999  face2423.jpg  face1524.jpg\n",
              "\n",
              "[3000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BsR76zuoQ4D"
      },
      "source": [
        "from arcface import ArcFace\n",
        "\n",
        "#cosine distance \n",
        "def cos_dist(x1,x2):\n",
        "  \"\"\"\n",
        "  Get cosine distance between 2 numpy arrays\n",
        "  \"\"\"\n",
        "  return np.dot(x1, x2) / (np.sqrt(np.dot(x1,x1)) * np.sqrt(np.dot(x2,x2)))\n",
        "\n",
        "\n",
        "def get_cosine_distance (img1,img2):\n",
        "  face_rec = ArcFace.ArcFace()\n",
        "  emb1 = face_rec.calc_emb(img1)\n",
        "  emb2 = face_rec.calc_emb(img2)\n",
        "\n",
        "  dist = cos_dist(emb1, emb2)\n",
        "  return dist\n",
        "test_path = \"/content/drive/MyDrive/Kinship Recognition Starter/test/\"\n",
        "\n",
        "\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Kinship Recognition Starter/test_ds.csv')\n",
        "\n",
        "predictions = []\n",
        "scores = []\n",
        "\n",
        "for i in range(0, len(submission)):\n",
        "    X1 = submission.p1[i]\n",
        "    #print(X1)\n",
        "    X1 = test_path + X1\n",
        "    \n",
        "\n",
        "    X2 = submission.p2[i]\n",
        "    X2 = test_path + X2 \n",
        "    backends = ['opencv', 'ssd', 'dlib', 'mtcnn', 'retinaface']\n",
        "\n",
        "    #face detection and alignment\n",
        "    detected_face = DeepFace.detectFace(\"img.jpg\", detector_backend = backends[4])\n",
        "    \n",
        "    similarity = get_cosine_distance(X1, X2)\n",
        "    pred = 0 \n",
        "    scores.append(similarity)\n",
        "    if similarity >= 0.65: pred = 1  \n",
        "       \n",
        "    predictions.append(pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcTdEqSkhIYx",
        "outputId": "a2baaa82-86e0-475e-c60f-380bab94a516"
      },
      "source": [
        "from deepface import DeepFace\n",
        "from deepface.commons.distance import findCosineDistance, findEuclideanDistance, l2_normalize\n",
        "from deepface.commons import functions\n",
        "from deepface.basemodels import ArcFace\n",
        "\n",
        "model = ArcFace.loadModel()\n",
        "model.load_weights(\"/content/drive/MyDrive/arcface_weights.h5\")\n",
        "\n",
        "test_path = \"/content/drive/MyDrive/Kinship Recognition Starter/test/\"\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Kinship Recognition Starter/test_ds.csv')\n",
        "\n",
        "cos_predictions, euc_pred, l2_pred = [], [], []\n",
        "cos, euc, l2 = [], [], []\n",
        "for i in range(0, len(submission)):\n",
        "    print(i)\n",
        "    X1 = submission.p1[i]\n",
        "    #print(X1)\n",
        "    X1 = test_path + X1\n",
        "    \n",
        "\n",
        "    X2 = submission.p2[i]\n",
        "    X2 = test_path + X2 \n",
        "\n",
        "    img1 = functions.preprocess_face(X1, target_size = (112, 112),enforce_detection=False)\n",
        "    img2 = functions.preprocess_face(X2, target_size = (112, 112),enforce_detection=False)\n",
        "    \n",
        "    img1_emb = model.predict(img1)[0]\n",
        "    img2_emb = model.predict(img2)[0]\n",
        "\n",
        "    distance = findCosineDistance(img1_emb, img2_emb)\n",
        "    cos.append(distance)\n",
        "    pred = 1 if distance >= .68 else 0 \n",
        "    cos_predictions.append(pred)\n",
        "    cos.append(distance)\n",
        "\n",
        "    distance = findEuclideanDistance(img1_emb, img2_emb)\n",
        "    pred=1 if distance <= 6.14 else  0 \n",
        "    euc_pred.append(pred)\n",
        "    euc.append(distance)\n",
        "\n",
        "    distance = findEuclideanDistance(l2_normalize(img1_emb), l2_normalize(img2_emb))\n",
        "    pred =1 if distance <= 1.5 else  0 \n",
        "    l2_pred.append(pred)\n",
        "    l2.append(distance) \n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1154\n",
            "1155\n",
            "1156\n",
            "1157\n",
            "1158\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1162\n",
            "1163\n",
            "1164\n",
            "1165\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n",
            "1188\n",
            "1189\n",
            "1190\n",
            "1191\n",
            "1192\n",
            "1193\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1198\n",
            "1199\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1209\n",
            "1210\n",
            "1211\n",
            "1212\n",
            "1213\n",
            "1214\n",
            "1215\n",
            "1216\n",
            "1217\n",
            "1218\n",
            "1219\n",
            "1220\n",
            "1221\n",
            "1222\n",
            "1223\n",
            "1224\n",
            "1225\n",
            "1226\n",
            "1227\n",
            "1228\n",
            "1229\n",
            "1230\n",
            "1231\n",
            "1232\n",
            "1233\n",
            "1234\n",
            "1235\n",
            "1236\n",
            "1237\n",
            "1238\n",
            "1239\n",
            "1240\n",
            "1241\n",
            "1242\n",
            "1243\n",
            "1244\n",
            "1245\n",
            "1246\n",
            "1247\n",
            "1248\n",
            "1249\n",
            "1250\n",
            "1251\n",
            "1252\n",
            "1253\n",
            "1254\n",
            "1255\n",
            "1256\n",
            "1257\n",
            "1258\n",
            "1259\n",
            "1260\n",
            "1261\n",
            "1262\n",
            "1263\n",
            "1264\n",
            "1265\n",
            "1266\n",
            "1267\n",
            "1268\n",
            "1269\n",
            "1270\n",
            "1271\n",
            "1272\n",
            "1273\n",
            "1274\n",
            "1275\n",
            "1276\n",
            "1277\n",
            "1278\n",
            "1279\n",
            "1280\n",
            "1281\n",
            "1282\n",
            "1283\n",
            "1284\n",
            "1285\n",
            "1286\n",
            "1287\n",
            "1288\n",
            "1289\n",
            "1290\n",
            "1291\n",
            "1292\n",
            "1293\n",
            "1294\n",
            "1295\n",
            "1296\n",
            "1297\n",
            "1298\n",
            "1299\n",
            "1300\n",
            "1301\n",
            "1302\n",
            "1303\n",
            "1304\n",
            "1305\n",
            "1306\n",
            "1307\n",
            "1308\n",
            "1309\n",
            "1310\n",
            "1311\n",
            "1312\n",
            "1313\n",
            "1314\n",
            "1315\n",
            "1316\n",
            "1317\n",
            "1318\n",
            "1319\n",
            "1320\n",
            "1321\n",
            "1322\n",
            "1323\n",
            "1324\n",
            "1325\n",
            "1326\n",
            "1327\n",
            "1328\n",
            "1329\n",
            "1330\n",
            "1331\n",
            "1332\n",
            "1333\n",
            "1334\n",
            "1335\n",
            "1336\n",
            "1337\n",
            "1338\n",
            "1339\n",
            "1340\n",
            "1341\n",
            "1342\n",
            "1343\n",
            "1344\n",
            "1345\n",
            "1346\n",
            "1347\n",
            "1348\n",
            "1349\n",
            "1350\n",
            "1351\n",
            "1352\n",
            "1353\n",
            "1354\n",
            "1355\n",
            "1356\n",
            "1357\n",
            "1358\n",
            "1359\n",
            "1360\n",
            "1361\n",
            "1362\n",
            "1363\n",
            "1364\n",
            "1365\n",
            "1366\n",
            "1367\n",
            "1368\n",
            "1369\n",
            "1370\n",
            "1371\n",
            "1372\n",
            "1373\n",
            "1374\n",
            "1375\n",
            "1376\n",
            "1377\n",
            "1378\n",
            "1379\n",
            "1380\n",
            "1381\n",
            "1382\n",
            "1383\n",
            "1384\n",
            "1385\n",
            "1386\n",
            "1387\n",
            "1388\n",
            "1389\n",
            "1390\n",
            "1391\n",
            "1392\n",
            "1393\n",
            "1394\n",
            "1395\n",
            "1396\n",
            "1397\n",
            "1398\n",
            "1399\n",
            "1400\n",
            "1401\n",
            "1402\n",
            "1403\n",
            "1404\n",
            "1405\n",
            "1406\n",
            "1407\n",
            "1408\n",
            "1409\n",
            "1410\n",
            "1411\n",
            "1412\n",
            "1413\n",
            "1414\n",
            "1415\n",
            "1416\n",
            "1417\n",
            "1418\n",
            "1419\n",
            "1420\n",
            "1421\n",
            "1422\n",
            "1423\n",
            "1424\n",
            "1425\n",
            "1426\n",
            "1427\n",
            "1428\n",
            "1429\n",
            "1430\n",
            "1431\n",
            "1432\n",
            "1433\n",
            "1434\n",
            "1435\n",
            "1436\n",
            "1437\n",
            "1438\n",
            "1439\n",
            "1440\n",
            "1441\n",
            "1442\n",
            "1443\n",
            "1444\n",
            "1445\n",
            "1446\n",
            "1447\n",
            "1448\n",
            "1449\n",
            "1450\n",
            "1451\n",
            "1452\n",
            "1453\n",
            "1454\n",
            "1455\n",
            "1456\n",
            "1457\n",
            "1458\n",
            "1459\n",
            "1460\n",
            "1461\n",
            "1462\n",
            "1463\n",
            "1464\n",
            "1465\n",
            "1466\n",
            "1467\n",
            "1468\n",
            "1469\n",
            "1470\n",
            "1471\n",
            "1472\n",
            "1473\n",
            "1474\n",
            "1475\n",
            "1476\n",
            "1477\n",
            "1478\n",
            "1479\n",
            "1480\n",
            "1481\n",
            "1482\n",
            "1483\n",
            "1484\n",
            "1485\n",
            "1486\n",
            "1487\n",
            "1488\n",
            "1489\n",
            "1490\n",
            "1491\n",
            "1492\n",
            "1493\n",
            "1494\n",
            "1495\n",
            "1496\n",
            "1497\n",
            "1498\n",
            "1499\n",
            "1500\n",
            "1501\n",
            "1502\n",
            "1503\n",
            "1504\n",
            "1505\n",
            "1506\n",
            "1507\n",
            "1508\n",
            "1509\n",
            "1510\n",
            "1511\n",
            "1512\n",
            "1513\n",
            "1514\n",
            "1515\n",
            "1516\n",
            "1517\n",
            "1518\n",
            "1519\n",
            "1520\n",
            "1521\n",
            "1522\n",
            "1523\n",
            "1524\n",
            "1525\n",
            "1526\n",
            "1527\n",
            "1528\n",
            "1529\n",
            "1530\n",
            "1531\n",
            "1532\n",
            "1533\n",
            "1534\n",
            "1535\n",
            "1536\n",
            "1537\n",
            "1538\n",
            "1539\n",
            "1540\n",
            "1541\n",
            "1542\n",
            "1543\n",
            "1544\n",
            "1545\n",
            "1546\n",
            "1547\n",
            "1548\n",
            "1549\n",
            "1550\n",
            "1551\n",
            "1552\n",
            "1553\n",
            "1554\n",
            "1555\n",
            "1556\n",
            "1557\n",
            "1558\n",
            "1559\n",
            "1560\n",
            "1561\n",
            "1562\n",
            "1563\n",
            "1564\n",
            "1565\n",
            "1566\n",
            "1567\n",
            "1568\n",
            "1569\n",
            "1570\n",
            "1571\n",
            "1572\n",
            "1573\n",
            "1574\n",
            "1575\n",
            "1576\n",
            "1577\n",
            "1578\n",
            "1579\n",
            "1580\n",
            "1581\n",
            "1582\n",
            "1583\n",
            "1584\n",
            "1585\n",
            "1586\n",
            "1587\n",
            "1588\n",
            "1589\n",
            "1590\n",
            "1591\n",
            "1592\n",
            "1593\n",
            "1594\n",
            "1595\n",
            "1596\n",
            "1597\n",
            "1598\n",
            "1599\n",
            "1600\n",
            "1601\n",
            "1602\n",
            "1603\n",
            "1604\n",
            "1605\n",
            "1606\n",
            "1607\n",
            "1608\n",
            "1609\n",
            "1610\n",
            "1611\n",
            "1612\n",
            "1613\n",
            "1614\n",
            "1615\n",
            "1616\n",
            "1617\n",
            "1618\n",
            "1619\n",
            "1620\n",
            "1621\n",
            "1622\n",
            "1623\n",
            "1624\n",
            "1625\n",
            "1626\n",
            "1627\n",
            "1628\n",
            "1629\n",
            "1630\n",
            "1631\n",
            "1632\n",
            "1633\n",
            "1634\n",
            "1635\n",
            "1636\n",
            "1637\n",
            "1638\n",
            "1639\n",
            "1640\n",
            "1641\n",
            "1642\n",
            "1643\n",
            "1644\n",
            "1645\n",
            "1646\n",
            "1647\n",
            "1648\n",
            "1649\n",
            "1650\n",
            "1651\n",
            "1652\n",
            "1653\n",
            "1654\n",
            "1655\n",
            "1656\n",
            "1657\n",
            "1658\n",
            "1659\n",
            "1660\n",
            "1661\n",
            "1662\n",
            "1663\n",
            "1664\n",
            "1665\n",
            "1666\n",
            "1667\n",
            "1668\n",
            "1669\n",
            "1670\n",
            "1671\n",
            "1672\n",
            "1673\n",
            "1674\n",
            "1675\n",
            "1676\n",
            "1677\n",
            "1678\n",
            "1679\n",
            "1680\n",
            "1681\n",
            "1682\n",
            "1683\n",
            "1684\n",
            "1685\n",
            "1686\n",
            "1687\n",
            "1688\n",
            "1689\n",
            "1690\n",
            "1691\n",
            "1692\n",
            "1693\n",
            "1694\n",
            "1695\n",
            "1696\n",
            "1697\n",
            "1698\n",
            "1699\n",
            "1700\n",
            "1701\n",
            "1702\n",
            "1703\n",
            "1704\n",
            "1705\n",
            "1706\n",
            "1707\n",
            "1708\n",
            "1709\n",
            "1710\n",
            "1711\n",
            "1712\n",
            "1713\n",
            "1714\n",
            "1715\n",
            "1716\n",
            "1717\n",
            "1718\n",
            "1719\n",
            "1720\n",
            "1721\n",
            "1722\n",
            "1723\n",
            "1724\n",
            "1725\n",
            "1726\n",
            "1727\n",
            "1728\n",
            "1729\n",
            "1730\n",
            "1731\n",
            "1732\n",
            "1733\n",
            "1734\n",
            "1735\n",
            "1736\n",
            "1737\n",
            "1738\n",
            "1739\n",
            "1740\n",
            "1741\n",
            "1742\n",
            "1743\n",
            "1744\n",
            "1745\n",
            "1746\n",
            "1747\n",
            "1748\n",
            "1749\n",
            "1750\n",
            "1751\n",
            "1752\n",
            "1753\n",
            "1754\n",
            "1755\n",
            "1756\n",
            "1757\n",
            "1758\n",
            "1759\n",
            "1760\n",
            "1761\n",
            "1762\n",
            "1763\n",
            "1764\n",
            "1765\n",
            "1766\n",
            "1767\n",
            "1768\n",
            "1769\n",
            "1770\n",
            "1771\n",
            "1772\n",
            "1773\n",
            "1774\n",
            "1775\n",
            "1776\n",
            "1777\n",
            "1778\n",
            "1779\n",
            "1780\n",
            "1781\n",
            "1782\n",
            "1783\n",
            "1784\n",
            "1785\n",
            "1786\n",
            "1787\n",
            "1788\n",
            "1789\n",
            "1790\n",
            "1791\n",
            "1792\n",
            "1793\n",
            "1794\n",
            "1795\n",
            "1796\n",
            "1797\n",
            "1798\n",
            "1799\n",
            "1800\n",
            "1801\n",
            "1802\n",
            "1803\n",
            "1804\n",
            "1805\n",
            "1806\n",
            "1807\n",
            "1808\n",
            "1809\n",
            "1810\n",
            "1811\n",
            "1812\n",
            "1813\n",
            "1814\n",
            "1815\n",
            "1816\n",
            "1817\n",
            "1818\n",
            "1819\n",
            "1820\n",
            "1821\n",
            "1822\n",
            "1823\n",
            "1824\n",
            "1825\n",
            "1826\n",
            "1827\n",
            "1828\n",
            "1829\n",
            "1830\n",
            "1831\n",
            "1832\n",
            "1833\n",
            "1834\n",
            "1835\n",
            "1836\n",
            "1837\n",
            "1838\n",
            "1839\n",
            "1840\n",
            "1841\n",
            "1842\n",
            "1843\n",
            "1844\n",
            "1845\n",
            "1846\n",
            "1847\n",
            "1848\n",
            "1849\n",
            "1850\n",
            "1851\n",
            "1852\n",
            "1853\n",
            "1854\n",
            "1855\n",
            "1856\n",
            "1857\n",
            "1858\n",
            "1859\n",
            "1860\n",
            "1861\n",
            "1862\n",
            "1863\n",
            "1864\n",
            "1865\n",
            "1866\n",
            "1867\n",
            "1868\n",
            "1869\n",
            "1870\n",
            "1871\n",
            "1872\n",
            "1873\n",
            "1874\n",
            "1875\n",
            "1876\n",
            "1877\n",
            "1878\n",
            "1879\n",
            "1880\n",
            "1881\n",
            "1882\n",
            "1883\n",
            "1884\n",
            "1885\n",
            "1886\n",
            "1887\n",
            "1888\n",
            "1889\n",
            "1890\n",
            "1891\n",
            "1892\n",
            "1893\n",
            "1894\n",
            "1895\n",
            "1896\n",
            "1897\n",
            "1898\n",
            "1899\n",
            "1900\n",
            "1901\n",
            "1902\n",
            "1903\n",
            "1904\n",
            "1905\n",
            "1906\n",
            "1907\n",
            "1908\n",
            "1909\n",
            "1910\n",
            "1911\n",
            "1912\n",
            "1913\n",
            "1914\n",
            "1915\n",
            "1916\n",
            "1917\n",
            "1918\n",
            "1919\n",
            "1920\n",
            "1921\n",
            "1922\n",
            "1923\n",
            "1924\n",
            "1925\n",
            "1926\n",
            "1927\n",
            "1928\n",
            "1929\n",
            "1930\n",
            "1931\n",
            "1932\n",
            "1933\n",
            "1934\n",
            "1935\n",
            "1936\n",
            "1937\n",
            "1938\n",
            "1939\n",
            "1940\n",
            "1941\n",
            "1942\n",
            "1943\n",
            "1944\n",
            "1945\n",
            "1946\n",
            "1947\n",
            "1948\n",
            "1949\n",
            "1950\n",
            "1951\n",
            "1952\n",
            "1953\n",
            "1954\n",
            "1955\n",
            "1956\n",
            "1957\n",
            "1958\n",
            "1959\n",
            "1960\n",
            "1961\n",
            "1962\n",
            "1963\n",
            "1964\n",
            "1965\n",
            "1966\n",
            "1967\n",
            "1968\n",
            "1969\n",
            "1970\n",
            "1971\n",
            "1972\n",
            "1973\n",
            "1974\n",
            "1975\n",
            "1976\n",
            "1977\n",
            "1978\n",
            "1979\n",
            "1980\n",
            "1981\n",
            "1982\n",
            "1983\n",
            "1984\n",
            "1985\n",
            "1986\n",
            "1987\n",
            "1988\n",
            "1989\n",
            "1990\n",
            "1991\n",
            "1992\n",
            "1993\n",
            "1994\n",
            "1995\n",
            "1996\n",
            "1997\n",
            "1998\n",
            "1999\n",
            "2000\n",
            "2001\n",
            "2002\n",
            "2003\n",
            "2004\n",
            "2005\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "2009\n",
            "2010\n",
            "2011\n",
            "2012\n",
            "2013\n",
            "2014\n",
            "2015\n",
            "2016\n",
            "2017\n",
            "2018\n",
            "2019\n",
            "2020\n",
            "2021\n",
            "2022\n",
            "2023\n",
            "2024\n",
            "2025\n",
            "2026\n",
            "2027\n",
            "2028\n",
            "2029\n",
            "2030\n",
            "2031\n",
            "2032\n",
            "2033\n",
            "2034\n",
            "2035\n",
            "2036\n",
            "2037\n",
            "2038\n",
            "2039\n",
            "2040\n",
            "2041\n",
            "2042\n",
            "2043\n",
            "2044\n",
            "2045\n",
            "2046\n",
            "2047\n",
            "2048\n",
            "2049\n",
            "2050\n",
            "2051\n",
            "2052\n",
            "2053\n",
            "2054\n",
            "2055\n",
            "2056\n",
            "2057\n",
            "2058\n",
            "2059\n",
            "2060\n",
            "2061\n",
            "2062\n",
            "2063\n",
            "2064\n",
            "2065\n",
            "2066\n",
            "2067\n",
            "2068\n",
            "2069\n",
            "2070\n",
            "2071\n",
            "2072\n",
            "2073\n",
            "2074\n",
            "2075\n",
            "2076\n",
            "2077\n",
            "2078\n",
            "2079\n",
            "2080\n",
            "2081\n",
            "2082\n",
            "2083\n",
            "2084\n",
            "2085\n",
            "2086\n",
            "2087\n",
            "2088\n",
            "2089\n",
            "2090\n",
            "2091\n",
            "2092\n",
            "2093\n",
            "2094\n",
            "2095\n",
            "2096\n",
            "2097\n",
            "2098\n",
            "2099\n",
            "2100\n",
            "2101\n",
            "2102\n",
            "2103\n",
            "2104\n",
            "2105\n",
            "2106\n",
            "2107\n",
            "2108\n",
            "2109\n",
            "2110\n",
            "2111\n",
            "2112\n",
            "2113\n",
            "2114\n",
            "2115\n",
            "2116\n",
            "2117\n",
            "2118\n",
            "2119\n",
            "2120\n",
            "2121\n",
            "2122\n",
            "2123\n",
            "2124\n",
            "2125\n",
            "2126\n",
            "2127\n",
            "2128\n",
            "2129\n",
            "2130\n",
            "2131\n",
            "2132\n",
            "2133\n",
            "2134\n",
            "2135\n",
            "2136\n",
            "2137\n",
            "2138\n",
            "2139\n",
            "2140\n",
            "2141\n",
            "2142\n",
            "2143\n",
            "2144\n",
            "2145\n",
            "2146\n",
            "2147\n",
            "2148\n",
            "2149\n",
            "2150\n",
            "2151\n",
            "2152\n",
            "2153\n",
            "2154\n",
            "2155\n",
            "2156\n",
            "2157\n",
            "2158\n",
            "2159\n",
            "2160\n",
            "2161\n",
            "2162\n",
            "2163\n",
            "2164\n",
            "2165\n",
            "2166\n",
            "2167\n",
            "2168\n",
            "2169\n",
            "2170\n",
            "2171\n",
            "2172\n",
            "2173\n",
            "2174\n",
            "2175\n",
            "2176\n",
            "2177\n",
            "2178\n",
            "2179\n",
            "2180\n",
            "2181\n",
            "2182\n",
            "2183\n",
            "2184\n",
            "2185\n",
            "2186\n",
            "2187\n",
            "2188\n",
            "2189\n",
            "2190\n",
            "2191\n",
            "2192\n",
            "2193\n",
            "2194\n",
            "2195\n",
            "2196\n",
            "2197\n",
            "2198\n",
            "2199\n",
            "2200\n",
            "2201\n",
            "2202\n",
            "2203\n",
            "2204\n",
            "2205\n",
            "2206\n",
            "2207\n",
            "2208\n",
            "2209\n",
            "2210\n",
            "2211\n",
            "2212\n",
            "2213\n",
            "2214\n",
            "2215\n",
            "2216\n",
            "2217\n",
            "2218\n",
            "2219\n",
            "2220\n",
            "2221\n",
            "2222\n",
            "2223\n",
            "2224\n",
            "2225\n",
            "2226\n",
            "2227\n",
            "2228\n",
            "2229\n",
            "2230\n",
            "2231\n",
            "2232\n",
            "2233\n",
            "2234\n",
            "2235\n",
            "2236\n",
            "2237\n",
            "2238\n",
            "2239\n",
            "2240\n",
            "2241\n",
            "2242\n",
            "2243\n",
            "2244\n",
            "2245\n",
            "2246\n",
            "2247\n",
            "2248\n",
            "2249\n",
            "2250\n",
            "2251\n",
            "2252\n",
            "2253\n",
            "2254\n",
            "2255\n",
            "2256\n",
            "2257\n",
            "2258\n",
            "2259\n",
            "2260\n",
            "2261\n",
            "2262\n",
            "2263\n",
            "2264\n",
            "2265\n",
            "2266\n",
            "2267\n",
            "2268\n",
            "2269\n",
            "2270\n",
            "2271\n",
            "2272\n",
            "2273\n",
            "2274\n",
            "2275\n",
            "2276\n",
            "2277\n",
            "2278\n",
            "2279\n",
            "2280\n",
            "2281\n",
            "2282\n",
            "2283\n",
            "2284\n",
            "2285\n",
            "2286\n",
            "2287\n",
            "2288\n",
            "2289\n",
            "2290\n",
            "2291\n",
            "2292\n",
            "2293\n",
            "2294\n",
            "2295\n",
            "2296\n",
            "2297\n",
            "2298\n",
            "2299\n",
            "2300\n",
            "2301\n",
            "2302\n",
            "2303\n",
            "2304\n",
            "2305\n",
            "2306\n",
            "2307\n",
            "2308\n",
            "2309\n",
            "2310\n",
            "2311\n",
            "2312\n",
            "2313\n",
            "2314\n",
            "2315\n",
            "2316\n",
            "2317\n",
            "2318\n",
            "2319\n",
            "2320\n",
            "2321\n",
            "2322\n",
            "2323\n",
            "2324\n",
            "2325\n",
            "2326\n",
            "2327\n",
            "2328\n",
            "2329\n",
            "2330\n",
            "2331\n",
            "2332\n",
            "2333\n",
            "2334\n",
            "2335\n",
            "2336\n",
            "2337\n",
            "2338\n",
            "2339\n",
            "2340\n",
            "2341\n",
            "2342\n",
            "2343\n",
            "2344\n",
            "2345\n",
            "2346\n",
            "2347\n",
            "2348\n",
            "2349\n",
            "2350\n",
            "2351\n",
            "2352\n",
            "2353\n",
            "2354\n",
            "2355\n",
            "2356\n",
            "2357\n",
            "2358\n",
            "2359\n",
            "2360\n",
            "2361\n",
            "2362\n",
            "2363\n",
            "2364\n",
            "2365\n",
            "2366\n",
            "2367\n",
            "2368\n",
            "2369\n",
            "2370\n",
            "2371\n",
            "2372\n",
            "2373\n",
            "2374\n",
            "2375\n",
            "2376\n",
            "2377\n",
            "2378\n",
            "2379\n",
            "2380\n",
            "2381\n",
            "2382\n",
            "2383\n",
            "2384\n",
            "2385\n",
            "2386\n",
            "2387\n",
            "2388\n",
            "2389\n",
            "2390\n",
            "2391\n",
            "2392\n",
            "2393\n",
            "2394\n",
            "2395\n",
            "2396\n",
            "2397\n",
            "2398\n",
            "2399\n",
            "2400\n",
            "2401\n",
            "2402\n",
            "2403\n",
            "2404\n",
            "2405\n",
            "2406\n",
            "2407\n",
            "2408\n",
            "2409\n",
            "2410\n",
            "2411\n",
            "2412\n",
            "2413\n",
            "2414\n",
            "2415\n",
            "2416\n",
            "2417\n",
            "2418\n",
            "2419\n",
            "2420\n",
            "2421\n",
            "2422\n",
            "2423\n",
            "2424\n",
            "2425\n",
            "2426\n",
            "2427\n",
            "2428\n",
            "2429\n",
            "2430\n",
            "2431\n",
            "2432\n",
            "2433\n",
            "2434\n",
            "2435\n",
            "2436\n",
            "2437\n",
            "2438\n",
            "2439\n",
            "2440\n",
            "2441\n",
            "2442\n",
            "2443\n",
            "2444\n",
            "2445\n",
            "2446\n",
            "2447\n",
            "2448\n",
            "2449\n",
            "2450\n",
            "2451\n",
            "2452\n",
            "2453\n",
            "2454\n",
            "2455\n",
            "2456\n",
            "2457\n",
            "2458\n",
            "2459\n",
            "2460\n",
            "2461\n",
            "2462\n",
            "2463\n",
            "2464\n",
            "2465\n",
            "2466\n",
            "2467\n",
            "2468\n",
            "2469\n",
            "2470\n",
            "2471\n",
            "2472\n",
            "2473\n",
            "2474\n",
            "2475\n",
            "2476\n",
            "2477\n",
            "2478\n",
            "2479\n",
            "2480\n",
            "2481\n",
            "2482\n",
            "2483\n",
            "2484\n",
            "2485\n",
            "2486\n",
            "2487\n",
            "2488\n",
            "2489\n",
            "2490\n",
            "2491\n",
            "2492\n",
            "2493\n",
            "2494\n",
            "2495\n",
            "2496\n",
            "2497\n",
            "2498\n",
            "2499\n",
            "2500\n",
            "2501\n",
            "2502\n",
            "2503\n",
            "2504\n",
            "2505\n",
            "2506\n",
            "2507\n",
            "2508\n",
            "2509\n",
            "2510\n",
            "2511\n",
            "2512\n",
            "2513\n",
            "2514\n",
            "2515\n",
            "2516\n",
            "2517\n",
            "2518\n",
            "2519\n",
            "2520\n",
            "2521\n",
            "2522\n",
            "2523\n",
            "2524\n",
            "2525\n",
            "2526\n",
            "2527\n",
            "2528\n",
            "2529\n",
            "2530\n",
            "2531\n",
            "2532\n",
            "2533\n",
            "2534\n",
            "2535\n",
            "2536\n",
            "2537\n",
            "2538\n",
            "2539\n",
            "2540\n",
            "2541\n",
            "2542\n",
            "2543\n",
            "2544\n",
            "2545\n",
            "2546\n",
            "2547\n",
            "2548\n",
            "2549\n",
            "2550\n",
            "2551\n",
            "2552\n",
            "2553\n",
            "2554\n",
            "2555\n",
            "2556\n",
            "2557\n",
            "2558\n",
            "2559\n",
            "2560\n",
            "2561\n",
            "2562\n",
            "2563\n",
            "2564\n",
            "2565\n",
            "2566\n",
            "2567\n",
            "2568\n",
            "2569\n",
            "2570\n",
            "2571\n",
            "2572\n",
            "2573\n",
            "2574\n",
            "2575\n",
            "2576\n",
            "2577\n",
            "2578\n",
            "2579\n",
            "2580\n",
            "2581\n",
            "2582\n",
            "2583\n",
            "2584\n",
            "2585\n",
            "2586\n",
            "2587\n",
            "2588\n",
            "2589\n",
            "2590\n",
            "2591\n",
            "2592\n",
            "2593\n",
            "2594\n",
            "2595\n",
            "2596\n",
            "2597\n",
            "2598\n",
            "2599\n",
            "2600\n",
            "2601\n",
            "2602\n",
            "2603\n",
            "2604\n",
            "2605\n",
            "2606\n",
            "2607\n",
            "2608\n",
            "2609\n",
            "2610\n",
            "2611\n",
            "2612\n",
            "2613\n",
            "2614\n",
            "2615\n",
            "2616\n",
            "2617\n",
            "2618\n",
            "2619\n",
            "2620\n",
            "2621\n",
            "2622\n",
            "2623\n",
            "2624\n",
            "2625\n",
            "2626\n",
            "2627\n",
            "2628\n",
            "2629\n",
            "2630\n",
            "2631\n",
            "2632\n",
            "2633\n",
            "2634\n",
            "2635\n",
            "2636\n",
            "2637\n",
            "2638\n",
            "2639\n",
            "2640\n",
            "2641\n",
            "2642\n",
            "2643\n",
            "2644\n",
            "2645\n",
            "2646\n",
            "2647\n",
            "2648\n",
            "2649\n",
            "2650\n",
            "2651\n",
            "2652\n",
            "2653\n",
            "2654\n",
            "2655\n",
            "2656\n",
            "2657\n",
            "2658\n",
            "2659\n",
            "2660\n",
            "2661\n",
            "2662\n",
            "2663\n",
            "2664\n",
            "2665\n",
            "2666\n",
            "2667\n",
            "2668\n",
            "2669\n",
            "2670\n",
            "2671\n",
            "2672\n",
            "2673\n",
            "2674\n",
            "2675\n",
            "2676\n",
            "2677\n",
            "2678\n",
            "2679\n",
            "2680\n",
            "2681\n",
            "2682\n",
            "2683\n",
            "2684\n",
            "2685\n",
            "2686\n",
            "2687\n",
            "2688\n",
            "2689\n",
            "2690\n",
            "2691\n",
            "2692\n",
            "2693\n",
            "2694\n",
            "2695\n",
            "2696\n",
            "2697\n",
            "2698\n",
            "2699\n",
            "2700\n",
            "2701\n",
            "2702\n",
            "2703\n",
            "2704\n",
            "2705\n",
            "2706\n",
            "2707\n",
            "2708\n",
            "2709\n",
            "2710\n",
            "2711\n",
            "2712\n",
            "2713\n",
            "2714\n",
            "2715\n",
            "2716\n",
            "2717\n",
            "2718\n",
            "2719\n",
            "2720\n",
            "2721\n",
            "2722\n",
            "2723\n",
            "2724\n",
            "2725\n",
            "2726\n",
            "2727\n",
            "2728\n",
            "2729\n",
            "2730\n",
            "2731\n",
            "2732\n",
            "2733\n",
            "2734\n",
            "2735\n",
            "2736\n",
            "2737\n",
            "2738\n",
            "2739\n",
            "2740\n",
            "2741\n",
            "2742\n",
            "2743\n",
            "2744\n",
            "2745\n",
            "2746\n",
            "2747\n",
            "2748\n",
            "2749\n",
            "2750\n",
            "2751\n",
            "2752\n",
            "2753\n",
            "2754\n",
            "2755\n",
            "2756\n",
            "2757\n",
            "2758\n",
            "2759\n",
            "2760\n",
            "2761\n",
            "2762\n",
            "2763\n",
            "2764\n",
            "2765\n",
            "2766\n",
            "2767\n",
            "2768\n",
            "2769\n",
            "2770\n",
            "2771\n",
            "2772\n",
            "2773\n",
            "2774\n",
            "2775\n",
            "2776\n",
            "2777\n",
            "2778\n",
            "2779\n",
            "2780\n",
            "2781\n",
            "2782\n",
            "2783\n",
            "2784\n",
            "2785\n",
            "2786\n",
            "2787\n",
            "2788\n",
            "2789\n",
            "2790\n",
            "2791\n",
            "2792\n",
            "2793\n",
            "2794\n",
            "2795\n",
            "2796\n",
            "2797\n",
            "2798\n",
            "2799\n",
            "2800\n",
            "2801\n",
            "2802\n",
            "2803\n",
            "2804\n",
            "2805\n",
            "2806\n",
            "2807\n",
            "2808\n",
            "2809\n",
            "2810\n",
            "2811\n",
            "2812\n",
            "2813\n",
            "2814\n",
            "2815\n",
            "2816\n",
            "2817\n",
            "2818\n",
            "2819\n",
            "2820\n",
            "2821\n",
            "2822\n",
            "2823\n",
            "2824\n",
            "2825\n",
            "2826\n",
            "2827\n",
            "2828\n",
            "2829\n",
            "2830\n",
            "2831\n",
            "2832\n",
            "2833\n",
            "2834\n",
            "2835\n",
            "2836\n",
            "2837\n",
            "2838\n",
            "2839\n",
            "2840\n",
            "2841\n",
            "2842\n",
            "2843\n",
            "2844\n",
            "2845\n",
            "2846\n",
            "2847\n",
            "2848\n",
            "2849\n",
            "2850\n",
            "2851\n",
            "2852\n",
            "2853\n",
            "2854\n",
            "2855\n",
            "2856\n",
            "2857\n",
            "2858\n",
            "2859\n",
            "2860\n",
            "2861\n",
            "2862\n",
            "2863\n",
            "2864\n",
            "2865\n",
            "2866\n",
            "2867\n",
            "2868\n",
            "2869\n",
            "2870\n",
            "2871\n",
            "2872\n",
            "2873\n",
            "2874\n",
            "2875\n",
            "2876\n",
            "2877\n",
            "2878\n",
            "2879\n",
            "2880\n",
            "2881\n",
            "2882\n",
            "2883\n",
            "2884\n",
            "2885\n",
            "2886\n",
            "2887\n",
            "2888\n",
            "2889\n",
            "2890\n",
            "2891\n",
            "2892\n",
            "2893\n",
            "2894\n",
            "2895\n",
            "2896\n",
            "2897\n",
            "2898\n",
            "2899\n",
            "2900\n",
            "2901\n",
            "2902\n",
            "2903\n",
            "2904\n",
            "2905\n",
            "2906\n",
            "2907\n",
            "2908\n",
            "2909\n",
            "2910\n",
            "2911\n",
            "2912\n",
            "2913\n",
            "2914\n",
            "2915\n",
            "2916\n",
            "2917\n",
            "2918\n",
            "2919\n",
            "2920\n",
            "2921\n",
            "2922\n",
            "2923\n",
            "2924\n",
            "2925\n",
            "2926\n",
            "2927\n",
            "2928\n",
            "2929\n",
            "2930\n",
            "2931\n",
            "2932\n",
            "2933\n",
            "2934\n",
            "2935\n",
            "2936\n",
            "2937\n",
            "2938\n",
            "2939\n",
            "2940\n",
            "2941\n",
            "2942\n",
            "2943\n",
            "2944\n",
            "2945\n",
            "2946\n",
            "2947\n",
            "2948\n",
            "2949\n",
            "2950\n",
            "2951\n",
            "2952\n",
            "2953\n",
            "2954\n",
            "2955\n",
            "2956\n",
            "2957\n",
            "2958\n",
            "2959\n",
            "2960\n",
            "2961\n",
            "2962\n",
            "2963\n",
            "2964\n",
            "2965\n",
            "2966\n",
            "2967\n",
            "2968\n",
            "2969\n",
            "2970\n",
            "2971\n",
            "2972\n",
            "2973\n",
            "2974\n",
            "2975\n",
            "2976\n",
            "2977\n",
            "2978\n",
            "2979\n",
            "2980\n",
            "2981\n",
            "2982\n",
            "2983\n",
            "2984\n",
            "2985\n",
            "2986\n",
            "2987\n",
            "2988\n",
            "2989\n",
            "2990\n",
            "2991\n",
            "2992\n",
            "2993\n",
            "2994\n",
            "2995\n",
            "2996\n",
            "2997\n",
            "2998\n",
            "2999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbKJBlhpnmMT"
      },
      "source": [
        "X1= '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID10/P10431_face3.jpg'\n",
        "X2 = '/content/drive/MyDrive/Kinship Recognition Starter/train/train-faces/F0990/MID9/P10437_face5.jpg'\n",
        "\n",
        "img1 = functions.preprocess_face(X1, target_size = (112, 112),enforce_detection=False)\n",
        "img2 = functions.preprocess_face(X2, target_size = (112, 112),enforce_detection=False)\n",
        "\n",
        "img1 = model.predict(img1)[0]\n",
        "img2= model.predict(img2)[0]\n",
        "\n",
        "distance = findCosineDistance(img1, img2)\n",
        "print(\"Cos \", distance)\n",
        "distance = findEuclideanDistance(img1, img2)\n",
        "print(\"eucl \", distance)\n",
        "distance = findEuclideanDistance(l2_normalize(img1), l2_normalize(img2))\n",
        "print(\"L2 \", distance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIeZINQzm_sV",
        "outputId": "142bb207-3716-4756-c399-62fcb45785c7"
      },
      "source": [
        "len(submission)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YEQ0Q6Ui6NP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f64527f-caf4-4261-b831-6473e558e9d5"
      },
      "source": [
        "file_path = \"/content/drive/MyDrive/af_model.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n",
        "\n",
        "reduce_on_plateau = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", factor=0.1, patience=20, verbose=1)\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_on_plateau]\n",
        "\n",
        "model = baseline_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.keras.engine.functional.Functional'>\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_27 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_28 (InputLayer)           [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "arcface_model (Functional)      (None, 512)          74978688    input_27[0][0]                   \n",
            "                                                                 input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "subtract_2 (Subtract)           (None, 512)          0           arcface_model[0][0]              \n",
            "                                                                 arcface_model[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_7 (Multiply)           (None, 512)          0           arcface_model[0][0]              \n",
            "                                                                 arcface_model[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_6 (Multiply)           (None, 512)          0           subtract_2[0][0]                 \n",
            "                                                                 subtract_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 1024)         0           multiply_7[0][0]                 \n",
            "                                                                 multiply_6[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 100)          102500      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 100)          0           dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 1)            101         dropout_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 75,081,289\n",
            "Trainable params: 102,601\n",
            "Non-trainable params: 74,978,688\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDQn3ZdZAnX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d46024-64f3-4f17-c0f9-4f6951ff6169"
      },
      "source": [
        "model.fit(gen(train, train_person_to_images_map, batch_size=16), use_multiprocessing=False,\n",
        "                validation_data=gen(val, val_person_to_images_map, batch_size=64), epochs=200, verbose=1,\n",
        "                workers=1, callbacks=callbacks_list, steps_per_epoch=100, validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "100/100 [==============================] - 69s 403ms/step - loss: 9.9858 - acc: 0.5175 - val_loss: 3.8429 - val_acc: 0.4613\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.46125, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 38s 384ms/step - loss: 8.4810 - acc: 0.5000 - val_loss: 3.4107 - val_acc: 0.4888\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.46125 to 0.48875, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 38s 386ms/step - loss: 8.4931 - acc: 0.5119 - val_loss: 3.3076 - val_acc: 0.4978\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.48875 to 0.49781, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 38s 384ms/step - loss: 7.2581 - acc: 0.5038 - val_loss: 3.1896 - val_acc: 0.5119\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.49781 to 0.51187, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 38s 387ms/step - loss: 7.4592 - acc: 0.4944 - val_loss: 3.1637 - val_acc: 0.5159\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.51187 to 0.51594, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 37s 370ms/step - loss: 7.5300 - acc: 0.5038 - val_loss: 2.8823 - val_acc: 0.5303\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.51594 to 0.53031, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 37s 377ms/step - loss: 7.3647 - acc: 0.4950 - val_loss: 2.7979 - val_acc: 0.5394\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.53031 to 0.53938, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 37s 375ms/step - loss: 6.9008 - acc: 0.5263 - val_loss: 2.7271 - val_acc: 0.5344\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.53938\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 38s 379ms/step - loss: 6.7596 - acc: 0.5081 - val_loss: 2.8653 - val_acc: 0.5225\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.53938\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 37s 373ms/step - loss: 6.6310 - acc: 0.5156 - val_loss: 2.7802 - val_acc: 0.5088\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.53938\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 6.5745 - acc: 0.5175 - val_loss: 2.4985 - val_acc: 0.5688\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.53938 to 0.56875, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 38s 379ms/step - loss: 6.1912 - acc: 0.5281 - val_loss: 2.5696 - val_acc: 0.5487\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.56875\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 36s 362ms/step - loss: 6.0781 - acc: 0.5031 - val_loss: 2.4179 - val_acc: 0.5722\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.56875 to 0.57219, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 37s 370ms/step - loss: 5.4456 - acc: 0.5531 - val_loss: 2.4882 - val_acc: 0.5697\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.57219\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 37s 370ms/step - loss: 5.5297 - acc: 0.5419 - val_loss: 2.4790 - val_acc: 0.5575\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.57219\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 36s 367ms/step - loss: 5.6873 - acc: 0.5400 - val_loss: 2.3964 - val_acc: 0.5697\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.57219\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 5.1905 - acc: 0.5475 - val_loss: 2.3849 - val_acc: 0.5478\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.57219\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 36s 367ms/step - loss: 5.0287 - acc: 0.5550 - val_loss: 2.3803 - val_acc: 0.5562\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.57219\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 35s 355ms/step - loss: 4.8117 - acc: 0.5675 - val_loss: 2.2174 - val_acc: 0.5713\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.57219\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 36s 367ms/step - loss: 5.2783 - acc: 0.5487 - val_loss: 2.1639 - val_acc: 0.5850\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.57219 to 0.58500, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 37s 374ms/step - loss: 4.7804 - acc: 0.5494 - val_loss: 2.1498 - val_acc: 0.5675\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.58500\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 36s 362ms/step - loss: 4.6159 - acc: 0.5650 - val_loss: 2.1474 - val_acc: 0.5841\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.58500\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 36s 362ms/step - loss: 4.4947 - acc: 0.5681 - val_loss: 2.0952 - val_acc: 0.5813\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.58500\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 4.3568 - acc: 0.5750 - val_loss: 2.0386 - val_acc: 0.6022\n",
            "\n",
            "Epoch 00024: val_acc improved from 0.58500 to 0.60219, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - 36s 366ms/step - loss: 4.5629 - acc: 0.5587 - val_loss: 2.1542 - val_acc: 0.5650\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.60219\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - 37s 370ms/step - loss: 4.3811 - acc: 0.5725 - val_loss: 2.0040 - val_acc: 0.6084\n",
            "\n",
            "Epoch 00026: val_acc improved from 0.60219 to 0.60844, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - 36s 363ms/step - loss: 4.4127 - acc: 0.5850 - val_loss: 1.9999 - val_acc: 0.6009\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.60844\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - 36s 366ms/step - loss: 4.1911 - acc: 0.5631 - val_loss: 1.9769 - val_acc: 0.5984\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.60844\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - 35s 356ms/step - loss: 4.2449 - acc: 0.5794 - val_loss: 2.0091 - val_acc: 0.5906\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.60844\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 4.2157 - acc: 0.5756 - val_loss: 1.9791 - val_acc: 0.6053\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.60844\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - 35s 354ms/step - loss: 3.7502 - acc: 0.5713 - val_loss: 1.9253 - val_acc: 0.6025\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.60844\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - 35s 357ms/step - loss: 3.9756 - acc: 0.5938 - val_loss: 1.9693 - val_acc: 0.6037\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.60844\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - 35s 352ms/step - loss: 3.8934 - acc: 0.5688 - val_loss: 1.8512 - val_acc: 0.6244\n",
            "\n",
            "Epoch 00033: val_acc improved from 0.60844 to 0.62437, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - 37s 369ms/step - loss: 3.9125 - acc: 0.5719 - val_loss: 1.8689 - val_acc: 0.6119\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.62437\n",
            "Epoch 35/200\n",
            "100/100 [==============================] - 35s 350ms/step - loss: 3.4764 - acc: 0.6037 - val_loss: 1.8818 - val_acc: 0.6094\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.62437\n",
            "Epoch 36/200\n",
            "100/100 [==============================] - 37s 368ms/step - loss: 3.5282 - acc: 0.5919 - val_loss: 1.8063 - val_acc: 0.6222\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.62437\n",
            "Epoch 37/200\n",
            "100/100 [==============================] - 35s 352ms/step - loss: 3.6547 - acc: 0.5825 - val_loss: 1.8229 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.62437\n",
            "Epoch 38/200\n",
            "100/100 [==============================] - 36s 362ms/step - loss: 3.3031 - acc: 0.6075 - val_loss: 1.8482 - val_acc: 0.6141\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.62437\n",
            "Epoch 39/200\n",
            "100/100 [==============================] - 36s 358ms/step - loss: 3.5693 - acc: 0.5888 - val_loss: 1.7955 - val_acc: 0.6169\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.62437\n",
            "Epoch 40/200\n",
            "100/100 [==============================] - 35s 356ms/step - loss: 3.3432 - acc: 0.5925 - val_loss: 1.8432 - val_acc: 0.6191\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.62437\n",
            "Epoch 41/200\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 3.2534 - acc: 0.6169 - val_loss: 1.7608 - val_acc: 0.6272\n",
            "\n",
            "Epoch 00041: val_acc improved from 0.62437 to 0.62719, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 42/200\n",
            "100/100 [==============================] - 36s 367ms/step - loss: 3.3148 - acc: 0.5981 - val_loss: 1.7736 - val_acc: 0.6288\n",
            "\n",
            "Epoch 00042: val_acc improved from 0.62719 to 0.62875, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 43/200\n",
            "100/100 [==============================] - 35s 357ms/step - loss: 3.3796 - acc: 0.5950 - val_loss: 1.7168 - val_acc: 0.6244\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.62875\n",
            "Epoch 44/200\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 3.3120 - acc: 0.5756 - val_loss: 1.7827 - val_acc: 0.6219\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.62875\n",
            "Epoch 45/200\n",
            "100/100 [==============================] - 35s 348ms/step - loss: 3.2395 - acc: 0.6062 - val_loss: 1.7980 - val_acc: 0.6141\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.62875\n",
            "Epoch 46/200\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 3.2931 - acc: 0.5913 - val_loss: 1.7202 - val_acc: 0.6216\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.62875\n",
            "Epoch 47/200\n",
            "100/100 [==============================] - 36s 363ms/step - loss: 2.9175 - acc: 0.6162 - val_loss: 1.7687 - val_acc: 0.6119\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.62875\n",
            "Epoch 48/200\n",
            "100/100 [==============================] - 35s 355ms/step - loss: 3.0185 - acc: 0.6075 - val_loss: 1.6945 - val_acc: 0.6294\n",
            "\n",
            "Epoch 00048: val_acc improved from 0.62875 to 0.62937, saving model to /content/drive/MyDrive/af_model.h5\n",
            "Epoch 49/200\n",
            "100/100 [==============================] - 37s 370ms/step - loss: 3.1080 - acc: 0.5781 - val_loss: 1.7511 - val_acc: 0.6097\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.62937\n",
            "Epoch 50/200\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 2.8866 - acc: 0.6075 - val_loss: 1.6769 - val_acc: 0.6100\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.62937\n",
            "Epoch 51/200\n",
            "100/100 [==============================] - 35s 352ms/step - loss: 2.8835 - acc: 0.6012 - val_loss: 1.7437 - val_acc: 0.6141\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.62937\n",
            "Epoch 52/200\n",
            "100/100 [==============================] - 36s 362ms/step - loss: 2.9679 - acc: 0.5950 - val_loss: 1.7197 - val_acc: 0.6119\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.62937\n",
            "Epoch 53/200\n",
            "100/100 [==============================] - 34s 347ms/step - loss: 2.8658 - acc: 0.5950 - val_loss: 1.6611 - val_acc: 0.6178\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.62937\n",
            "Epoch 54/200\n",
            "100/100 [==============================] - 36s 363ms/step - loss: 2.6756 - acc: 0.6156 - val_loss: 1.6740 - val_acc: 0.6206\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.62937\n",
            "Epoch 55/200\n",
            "100/100 [==============================] - ETA: 0s - loss: 2.9518 - acc: 0.5694"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIl075HvEfAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40edfbb-c133-4d7b-8eff-0ad2068088ed"
      },
      "source": [
        "# Modify paths as per your need\n",
        "test_path = \"/content/drive/MyDrive/Kinship Recognition Starter/test/\"\n",
        "\n",
        "model = baseline_model()\n",
        "model.load_weights(\"/content/drive/MyDrive/baseline_model.h5\")\n",
        "\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Kinship Recognition Starter/test_ds.csv')\n",
        "predictions = []\n",
        "scores = []\n",
        "for i in range(0, len(submission.p1.values), 32):\n",
        "    X1 = submission.p1.values[i:i+32]\n",
        "    X1 = np.array([read_img(test_path + x) for x in X1])\n",
        "\n",
        "    X2 = submission.p2.values[i:i+32]\n",
        "    X2 = np.array([read_img(test_path + x) for x in X2])\n",
        "\n",
        "    pred = model.predict([X1, X2]).ravel().tolist()\n",
        "    predictions += pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_212), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/kernel:0' shape=(7, 7, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_212), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_213), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/kernel:0' shape=(1, 1, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_213), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_214), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_214), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_215), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_216), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_215), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_216), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_217), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_217), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_218), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_218), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_219), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_219), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_220), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_220), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_221), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_221), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_222), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_222), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_223), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/kernel:0' shape=(1, 1, 256, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_223), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_224), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_224), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_225), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/kernel:0' shape=(1, 1, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_226), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_225), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_226), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_227), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_227), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_228), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_228), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_229), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_229), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_230), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_230), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_231), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_231), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_232), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_232), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_233), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_233), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_234), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_234), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_235), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_235), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_236), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/kernel:0' shape=(1, 1, 512, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_236), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_237), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_237), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_238), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/kernel:0' shape=(1, 1, 512, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_239), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_238), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_239), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_240), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_240), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_241), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_241), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_242), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_242), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_243), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_243), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_244), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_244), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_245), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_245), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_246), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_246), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_247), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_247), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_248), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_248), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_249), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_249), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_250), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_250), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_251), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_251), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_252), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_252), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_253), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_253), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_254), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_254), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_255), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/kernel:0' shape=(1, 1, 1024, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_255), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_256), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_256), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_257), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/kernel:0' shape=(1, 1, 1024, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_258), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_257), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_258), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_259), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_259), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_260), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_260), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_261), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_261), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_262), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_262), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_263), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_263), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_264), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_264), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_265), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/kernel:0' shape=(7, 7, 3, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_265), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv1/7x7_s2/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_266), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/kernel:0' shape=(1, 1, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_266), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_267), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_267), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_268), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_269), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_268), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_269), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_1_1x1_proj/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_270), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_270), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_271), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_271), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_272), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_272), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_2_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_273), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/kernel:0' shape=(1, 1, 256, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_273), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_reduce/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_274), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/kernel:0' shape=(3, 3, 64, 64) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_274), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_3x3/bn/gamma:0' shape=(64,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_3x3/bn/beta:0' shape=(64,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_275), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/kernel:0' shape=(1, 1, 64, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_275), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv2_3_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_276), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/kernel:0' shape=(1, 1, 256, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_276), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_277), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_277), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_278), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/kernel:0' shape=(1, 1, 256, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_279), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_278), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_279), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_1_1x1_proj/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_280), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_280), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_281), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_281), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_282), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_282), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_2_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_283), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_283), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_284), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_284), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_285), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_285), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_3_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_286), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/kernel:0' shape=(1, 1, 512, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_286), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_287), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_287), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_3x3/bn/gamma:0' shape=(128,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_3x3/bn/beta:0' shape=(128,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_288), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/kernel:0' shape=(1, 1, 128, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_288), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv3_4_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_289), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/kernel:0' shape=(1, 1, 512, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_289), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_290), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_290), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_291), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/kernel:0' shape=(1, 1, 512, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_292), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_291), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_292), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_1_1x1_proj/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_293), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_293), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_294), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_294), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_295), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_295), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_2_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_296), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_296), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_297), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_297), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_298), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_298), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_3_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_299), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_299), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_300), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_300), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_301), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_301), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_4_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_302), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_302), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_303), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_303), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_304), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_304), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_5_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_305), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/kernel:0' shape=(1, 1, 1024, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_305), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_306), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_306), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_3x3/bn/gamma:0' shape=(256,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_3x3/bn/beta:0' shape=(256,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_307), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/kernel:0' shape=(1, 1, 256, 1024) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_307), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/gamma:0' shape=(1024,) dtype=float32>\n",
            "  <tf.Variable 'conv4_6_1x1_increase/bn/beta:0' shape=(1024,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_308), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/kernel:0' shape=(1, 1, 1024, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_308), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_309), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_309), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_310), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/kernel:0' shape=(1, 1, 1024, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_311), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_310), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_311), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_1_1x1_proj/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_312), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_312), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_313), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_313), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_314), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_314), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_2_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_315), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/kernel:0' shape=(1, 1, 2048, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_315), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_reduce/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_316), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/kernel:0' shape=(3, 3, 512, 512) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_316), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_3x3/bn/gamma:0' shape=(512,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_3x3/bn/beta:0' shape=(512,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.nn.convolution_317), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/kernel:0' shape=(1, 1, 512, 2048) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "WARNING:tensorflow:\n",
            "The following Variables were used a Lambda layer's call (tf.compat.v1.nn.fused_batch_norm_317), but\n",
            "are not present in its tracked objects:\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/gamma:0' shape=(2048,) dtype=float32>\n",
            "  <tf.Variable 'conv5_3_1x1_increase/bn/beta:0' shape=(2048,) dtype=float32>\n",
            "It is possible that this is intended behavior, but it is more likely\n",
            "an omission. This is a strong indication that this layer should be\n",
            "formulated as a subclassed Layer rather than a Lambda layer.\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_212 (TFOpLamb (None, 112, 112, 64) 0           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_265 (TFOpLamb (None, 112, 112, 64) 0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 112, 112, 64 0           tf.nn.convolution_212[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 112, 112, 64 0           tf.nn.convolution_265[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_196 (TFOpLambda)     (None, 112, 112, 64) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_245 (TFOpLambda)     (None, 112, 112, 64) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_4 (TFO (None, 55, 55, 64)   0           tf.nn.relu_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.max_pool_5 (TFO (None, 55, 55, 64)   0           tf.nn.relu_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_213 (TFOpLamb (None, 55, 55, 64)   0           tf.compat.v1.nn.max_pool_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_266 (TFOpLamb (None, 55, 55, 64)   0           tf.compat.v1.nn.max_pool_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_213[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_266[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_197 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_246 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_214 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_197[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_267 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_214[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_267[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_198 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_247 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_216 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_198[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_215 (TFOpLamb (None, 55, 55, 256)  0           tf.compat.v1.nn.max_pool_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_269 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_268 (TFOpLamb (None, 55, 55, 256)  0           tf.compat.v1.nn.max_pool_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_216[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_215[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_269[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_268[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_64 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_80 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_199 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_64[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_248 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_80[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_217 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_270 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_217[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_270[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_200 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_249 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_218 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_200[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_271 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_218[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_271[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_201 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_250 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_219 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_201[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_272 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_219[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_272[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_65 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_199[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_81 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_202 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_65[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_251 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_81[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_220 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_273 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_220[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_273[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_203 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_252 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_221 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_203[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_274 (TFOpLamb (None, 55, 55, 64)   0           tf.nn.relu_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_221[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 64), 0           tf.nn.convolution_274[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_204 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_253 (TFOpLambda)     (None, 55, 55, 64)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_222 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_275 (TFOpLamb (None, 55, 55, 256)  0           tf.nn.relu_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_222[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 55, 55, 256) 0           tf.nn.convolution_275[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_66 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_202[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_82 (TFOpLa (None, 55, 55, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_205 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_66[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_254 (TFOpLambda)     (None, 55, 55, 256)  0           tf.__operators__.add_82[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_223 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_276 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_223[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_276[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_206 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_255 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_224 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_277 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_224[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_277[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_207 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_256 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_226 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_225 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_279 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_278 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_226[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_225[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_279[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_278[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_67 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_83 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_208 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_67[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_257 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_83[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_227 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_280 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_227[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_280[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_209 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_258 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_228 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_281 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_228[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_281[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_210 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_259 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_229 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_282 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_229[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_282[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_68 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_84 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_211 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_68[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_260 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_84[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_230 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_283 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_230[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_283[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_212 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_261 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_231 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_212[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_284 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_231[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_284[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_213 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_262 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_232 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_285 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_232[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_285[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_69 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_85 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_214 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_69[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_263 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_85[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_233 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_286 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_233[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_286[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_215 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_264 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_234 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_287 (TFOpLamb (None, 28, 28, 128)  0           tf.nn.relu_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_234[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 128) 0           tf.nn.convolution_287[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_216 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_265 (TFOpLambda)     (None, 28, 28, 128)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_235 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_288 (TFOpLamb (None, 28, 28, 512)  0           tf.nn.relu_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_235[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 28, 28, 512) 0           tf.nn.convolution_288[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_70 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_86 (TFOpLa (None, 28, 28, 512)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_217 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_70[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_266 (TFOpLambda)     (None, 28, 28, 512)  0           tf.__operators__.add_86[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_236 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_289 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_236[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_289[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_218 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_267 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_237 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_290 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_237[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_290[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_219 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_268 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_239 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_238 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_292 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_291 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_239[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_238[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_292[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_291[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_71 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_87 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_220 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_71[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_269 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_87[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_240 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_293 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_240[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_293[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_221 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_270 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_241 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_221[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_294 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_270[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_241[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_294[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_222 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_271 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_242 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_295 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_242[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_295[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_72 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_88 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_223 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_72[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_272 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_88[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_243 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_296 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_243[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_296[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_224 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_273 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_244 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_297 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_244[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_297[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_225 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_274 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_245 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_298 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_245[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_298[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_73 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_89 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_226 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_73[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_275 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_89[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_246 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_299 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_246[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_299[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_227 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_276 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_247 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_300 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_247[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_300[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_228 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_277 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_248 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_301 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_248[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_301[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_74 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_90 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_229 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_74[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_278 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_90[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_249 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_302 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_249[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_302[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_230 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_279 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_250 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_303 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_250[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_303[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_231 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_280 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_251 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_304 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_251[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_304[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_75 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_91 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_232 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_75[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_281 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_91[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_252 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_305 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_252[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_305[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_233 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_282 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_253 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_306 (TFOpLamb (None, 14, 14, 256)  0           tf.nn.relu_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_253[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 256) 0           tf.nn.convolution_306[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_234 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_283 (TFOpLambda)     (None, 14, 14, 256)  0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_254 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_307 (TFOpLamb (None, 14, 14, 1024) 0           tf.nn.relu_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_254[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 14, 14, 1024 0           tf.nn.convolution_307[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_76 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_92 (TFOpLa (None, 14, 14, 1024) 0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_235 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_76[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_284 (TFOpLambda)     (None, 14, 14, 1024) 0           tf.__operators__.add_92[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_255 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_308 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_255[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_308[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_236 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_285 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_256 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_236[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_309 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_256[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_309[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_237 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_286 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_258 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_257 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_311 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_310 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_258[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_257[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_311[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_310[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_77 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_93 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_238 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_77[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_287 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_93[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_259 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_312 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_259[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_312[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_239 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_288 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_260 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_313 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_260[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_313[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_240 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_289 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_261 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_314 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_261[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_314[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_78 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_94 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_241 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_78[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_290 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_94[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_262 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_315 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_262[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_315[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_242 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_291 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_263 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_316 (TFOpLamb (None, 7, 7, 512)    0           tf.nn.relu_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_263[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 512),  0           tf.nn.convolution_316[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_243 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_292 (TFOpLambda)     (None, 7, 7, 512)    0           tf.compat.v1.nn.fused_batch_norm_\n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_264 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.convolution_317 (TFOpLamb (None, 7, 7, 2048)   0           tf.nn.relu_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_264[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.fused_batch_nor ((None, 7, 7, 2048), 0           tf.nn.convolution_317[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_79 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_95 (TFOpLa (None, 7, 7, 2048)   0           tf.compat.v1.nn.fused_batch_norm_\n",
            "                                                                 tf.nn.relu_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_244 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_79[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_293 (TFOpLambda)     (None, 7, 7, 2048)   0           tf.__operators__.add_95[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.avg_pool_4 (TFO (None, 1, 1, 2048)   0           tf.nn.relu_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.compat.v1.nn.avg_pool_5 (TFO (None, 1, 1, 2048)   0           tf.nn.relu_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_4 (GlobalM (None, 2048)         0           tf.compat.v1.nn.avg_pool_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 2048)         0           tf.compat.v1.nn.avg_pool_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_5 (GlobalM (None, 2048)         0           tf.compat.v1.nn.avg_pool_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_5 (Glo (None, 2048)         0           tf.compat.v1.nn.avg_pool_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 4096)         0           global_max_pooling2d_4[0][0]     \n",
            "                                                                 global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 4096)         0           global_max_pooling2d_5[0][0]     \n",
            "                                                                 global_average_pooling2d_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "subtract_2 (Subtract)           (None, 4096)         0           concatenate_6[0][0]              \n",
            "                                                                 concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_5 (Multiply)           (None, 4096)         0           concatenate_6[0][0]              \n",
            "                                                                 concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, 4096)         0           subtract_2[0][0]                 \n",
            "                                                                 subtract_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 8192)         0           multiply_5[0][0]                 \n",
            "                                                                 multiply_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 100)          819300      concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 100)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            101         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 819,401\n",
            "Trainable params: 819,401\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXyzufq7iZ1g"
      },
      "source": [
        "The final predictions will need to be rounded: EG 0.01 rounded to 0 and 0.78 rounded to 1. The simple .round() function is sufficient as below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkFEH-uva9c_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8345cd5-bf63-40ae-c46a-587339dd359c"
      },
      "source": [
        "print(len(cos_predictions))\n",
        "d = {'index': np.arange(0, 3000, 1), 'label':cos_predictions}\n",
        "submissionfile = pd.DataFrame(data=d)\n",
        "#submissionfile = submissionfile.round()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLp47gRy0YaA",
        "outputId": "276ff08c-dbb3-4bda-faab-53cfc3727dd7"
      },
      "source": [
        "print(len(cos), len(euc), len(l2))\n",
        "d = {'index': np.arange(0, 3000, 1), 'cos':new}\n",
        "f = pd.DataFrame(data=d)  \n",
        "f.to_csv(\"/content/drive/MyDrive/kinship_test/deepface_cosdistances.csv\", index=False) "
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6000 3000 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EbbawPYrchP"
      },
      "source": [
        "submissionfile.to_csv(\"/content/drive/MyDrive/kinship_test/c.wilkerson_ksc2138.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhmkS9DKxFrt"
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.read_csv(\"/content/drive/MyDrive/kinship_test/cw3329_ksc2138.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp_0Mkvwxt1R"
      },
      "source": [
        "submissionfile.astype('int64').to_csv(\"/content/drive/MyDrive/kinship_test/deepface_cos.csv\", index=False)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MafYixfL6ZbG"
      },
      "source": [
        "new = cos[::2]"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TguoeVwf6dY0",
        "outputId": "161342b9-3673-494c-9248-c81bb0ac31c9"
      },
      "source": [
        "print(len(new))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNodVS9W4NMB"
      },
      "source": [
        "At this point, download the CSV and submit it on Kaggle to score your predictions.\n"
      ]
    }
  ]
}