{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KinshipRecognition_FaceNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4g8yMLqtS3W"
      },
      "source": [
        "# **Kinship Prediction - Submission Notebook**\n",
        "\n",
        "### Kerry Cook, Chris Wilkerson\n",
        "\n",
        "We included 3 sections that contain the main different methods we tried in this competition. Our best submission is the the first section, which included ensemble methods with gradient boosting. \n",
        "\n",
        "A very close second was just using a pretrained network (Facenet) to calculate image embeddings, and use the L2 norm distance between two images for classification. \n",
        "\n",
        "The last section includes our efforts to improve the facenet prediction with transfer learning.\n",
        "\n",
        "1. Gradient Boosting and Ensemble Prediction\n",
        "2. Pretrained Facenet Network\n",
        "3. Transfer Learning \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjYhbL1xxgfU",
        "outputId": "99ea4ab3-73fd-46c9-c0f4-4e505243e14d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ribPmcZau-vR"
      },
      "source": [
        "Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS3ZhSjIAGgt"
      },
      "source": [
        "%%capture\n",
        "!pip install deepface"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4yFxckrAAZx"
      },
      "source": [
        "\n",
        "from collections import defaultdict\n",
        "from glob import glob\n",
        "from random import choice, sample\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Multiply, Dropout, Subtract\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import load_model\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF0H95sMQb9t",
        "outputId": "79f12782-2512-4b2b-883a-e144c96cb4a8"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5k69UJzvb26"
      },
      "source": [
        "Helper function to normalize images before predicition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4qAvVQqmCDY"
      },
      "source": [
        "def normalize(x):\n",
        "    if x.ndim == 4:\n",
        "        axis = (1, 2, 3)\n",
        "        size = x[0].size\n",
        "    elif x.ndim == 3:\n",
        "        axis = (0, 1, 2)\n",
        "        size = x.size\n",
        "    else:\n",
        "        raise ValueError('Dimension should be 3 or 4')\n",
        "\n",
        "    mean = np.mean(x, axis=axis, keepdims=True)\n",
        "    std = np.std(x, axis=axis, keepdims=True)\n",
        "    std_adj = np.maximum(std, 1.0/np.sqrt(size))\n",
        "    y = (x - mean) / std_adj\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqYdf4EoLZ_7"
      },
      "source": [
        "# 1. Gradient Boost + Ensemble Methods - Best Score "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMF0hWE4UcGA"
      },
      "source": [
        "# 2. Pretrained Facenet embedding with L2 Norm - No transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC3TNCLWx5RC"
      },
      "source": [
        "The cell below uses a pre-trained facenet model that was trained using the MS-Celeb-1M dataset (https://drive.google.com/drive/folders/12aMYASGCKvDdkygSv1yQq8ns03AStDO_).\n",
        "\n",
        "We calculated the embedding for each image, then calculated the cosine similarity, euclidean distance, and L2 normalized euclidean distance to test which performed best. The l2 distance performed the best on both the submission set and training data. In addition, we tried convering the distances to probabilities, which boosted accuracy by 2%. \n",
        "\n",
        "Before feeding the images to the network, they are preprocessed using deepface's preprocessing library to detect faces and reshape the image. This submission recevied a score of 69.866% on Kaggle, and were not able to improve with transfer learning, even when trying to expand the training pairs and add data augmentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcTdEqSkhIYx"
      },
      "source": [
        "from deepface.commons import functions\n",
        "from deepface.commons.distance import findCosineDistance, findEuclideanDistance, l2_normalize\n",
        "\n",
        "model_path = '/content/drive/MyDrive/kinship_test/models/facenet_keras.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "test_path = \"/content/drive/MyDrive/Kinship Recognition Starter/test/\"\n",
        "submission = pd.read_csv('/content/drive/MyDrive/Kinship Recognition Starter/test_ds.csv')\n",
        "\n",
        "cos_predictions, euc_pred, l2_pred = [], [], []\n",
        "cos, euc, l2 = [], [], []\n",
        "for i in range(0, len(submission)):\n",
        "  \n",
        "    X1 = submission.p1[i]\n",
        "    X1 = test_path + X1\n",
        "    \n",
        "\n",
        "    X2 = submission.p2[i]\n",
        "    X2 = test_path + X2 \n",
        "\n",
        "    #Process Image and detect faces \n",
        "    img1 = normalize(functions.preprocess_face(X1, target_size = (160, 160),enforce_detection=False))\n",
        "    img2 = normalize(functions.preprocess_face(X2, target_size = (160, 160),enforce_detection=False))\n",
        "    \n",
        "    #Cacluate image embedding from pre trained network\n",
        "    img1_emb = model.predict(img1)[0]\n",
        "    img2_emb = model.predict(img2)[0]\n",
        "\n",
        "    #Calculate both cosine distance and threshold pred\n",
        "    distance = findCosineDistance(img1_emb, img2_emb)\n",
        "    pred = 1 if distance >= .68 else 0 \n",
        "    cos_predictions.append(pred)\n",
        "    cos.append(distance)\n",
        "\n",
        "    #Euclid distance and threshold prediction\n",
        "    distance = findEuclideanDistance(img1_emb, img2_emb)\n",
        "    pred=1 if distance <= 6.14 else  0 \n",
        "    euc_pred.append(pred)\n",
        "    euc.append(distance)\n",
        "\n",
        "    #L2 Euclid distance and threshold prediction\n",
        "    distance = findEuclideanDistance(l2_normalize(img1_emb), l2_normalize(img2_emb))\n",
        "    pred =1 if distance <= 1.35 else  0 \n",
        "    l2_pred.append(pred)\n",
        "    l2.append(distance) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyrLNnh8ZvAE"
      },
      "source": [
        "#Convert distances into probabilities for prediction \n",
        "l2_sum = sum(l2)\n",
        "l2 = np.array(l2)\n",
        "\n",
        "l2_prob = []\n",
        "for d in l2:\n",
        "  prob = np.sum(l2[np.where(l2 <= d)[0]])/l2_sum\n",
        "  l2_prob.append(1 - prob)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkFEH-uva9c_"
      },
      "source": [
        "#Save all the threshold prediction files \n",
        "d = {'index': np.arange(0, 3000, 1), 'label':cos_predictions}\n",
        "submissionfile = pd.DataFrame(data=d)\n",
        "submissionfile.astype('int64').to_csv(\"/content/drive/MyDrive/kinship_test/transfer_learning/facenet_cos.csv\", index=False)\n",
        "\n",
        "d = {'index': np.arange(0, 3000, 1), 'label':euc_pred}\n",
        "submissionfile = pd.DataFrame(data=d)\n",
        "submissionfile.astype('int64').to_csv(\"/content/drive/MyDrive/kinship_test/transfer_learning/facenet_euc.csv\", index=False)\n",
        "\n",
        "\n",
        "d = {'index': np.arange(0, 3000, 1), 'label':l2_pred}\n",
        "submissionfile = pd.DataFrame(data=d)\n",
        "submissionfile.astype('int64').to_csv(\"/content/drive/MyDrive/kinship_test/transfer_learning/facenet_l2.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "463DBNl1Vu8Y"
      },
      "source": [
        "#Save distance calculation files \n",
        "d = {'index': np.arange(0, 3000, 1), 'label':cos}\n",
        "submissionfile = pd.DataFrame(data=d)\n",
        "submissionfile.to_csv(\"/content/drive/MyDrive/kinship_test/transfer_learning/dist_cos.csv\", index=False)\n",
        "\n",
        "d = {'index': np.arange(0, 3000, 1), 'label':euc}\n",
        "submissionfile = pd.DataFrame(data=d)\n",
        "submissionfile.to_csv(\"/content/drive/MyDrive/kinship_test/transfer_learning/dist_euc.csv\", index=False)\n",
        "\n",
        "\n",
        "d = {'index': np.arange(0, 3000, 1), 'label':l2}\n",
        "submissionfile = pd.DataFrame(data=d)\n",
        "submissionfile.to_csv(\"/content/drive/MyDrive/kinship_test/transfer_learning/dist_l2.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEjq27n8KDS7"
      },
      "source": [
        "The probability file is the file used for submission - picking a threshold of .55 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnfPPp2GvDfR"
      },
      "source": [
        "#Save L2 dist probability file - this is used for submission \n",
        "d = {'index': np.arange(0, 3000, 1), 'label':l2_prob}\n",
        "submissionfile = pd.DataFrame(data=d)\n",
        "submissionfile.to_csv(\"/content/drive/MyDrive/kinship_test/prob_l2.csv\", index=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIGNtQ-ALja6"
      },
      "source": [
        "# 3. Transfer Learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjR1FFBALlww"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}